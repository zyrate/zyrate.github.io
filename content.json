{"meta":{"title":"ZYR的博客","subtitle":"为者常成，行者常至","description":"","author":"Yunrui Zheng","url":"https://zyrate.github.io","root":"/"},"pages":[],"posts":[{"title":"MIT6.830 学习笔记 · Lab 1","slug":"Lab 1","date":"2023-07-07T12:09:15.630Z","updated":"2023-07-06T02:43:11.000Z","comments":true,"path":"2023/07/07/Lab 1/","link":"","permalink":"https://zyrate.github.io/2023/07/07/Lab%201/","excerpt":"6.830 是 MIT 的一门数据库课程，它的 Lab 是用 Java 写一个简易的数据库 SimpleDB。 Lab1 总共有 6 个 exercise，主要是练习的是数据库的数据存储部分。","text":"6.830 是 MIT 的一门数据库课程，它的 Lab 是用 Java 写一个简易的数据库 SimpleDB。 Lab1 总共有 6 个 exercise，主要是练习的是数据库的数据存储部分。 Exercise 1 src/java/simpledb/storage/TupleDesc.java src/java/simpledb/storage/Tuple.java 在 SimpleDB 中，逻辑上的存储单元由大到小分别是 Database -&gt; Table -&gt; Tuple -&gt; Field。一个表中的每一条记录就是一个 Tuple 元组对象，元组中的每一列是一个 Field 字段值，目前只实现了 Int 和 String（固定长度）类型。 每个元组需要一个 TupleDesc 对象来描述该元组包含的所有字段，包括每个字段类型 fieldType 和字段名 fieldName，在 SimpleDB 中由 TDItem 对象存储。 在实现 TupleDesc 的 toString() 方法时，发现了一个显而易见但之前没注意到的问题：集合每次在调用 iterator() 方法时都会生成一个新的 Iterator，所以不能反复调用此方法。另外 for-each 语句不能用于 Iterator，只能用于数组或实现了 Iterable 接口的对象。 Exercise 2 src/java/simpledb/common/Catalog.java Catalog 是管理数据库所有表的单例对象，比较简单。 主要实现了供外界调用的 addTable、getTableName 等方法 在 SimpleDB 中，一个 Table 对应一个 DbFile，并且共享同一个 ID（DbFile 绝对路径的 hashcode） 这里的 HashMap 用并发安全的比较好 Exercise 3 src/java/simpledb/storage/BufferPool.java 实现 getPage() 方法 BufferPool 也是一个全局单例对象，它负责维护访问页面 Page 的缓存。关于页面，有三个容易混淆的概念： 硬盘中的页面（也可以叫块 block） 操作系统中的页面 数据库中的页面Page 是数据库向硬盘中读取和写入一次数据的最小单位，一般来说数据库的页面比底层的页面要大一些，所以需要我们自己写一些逻辑来保证操作的原子性（暂时不需要）。 每次通过 PageId（存储 tableId 和 pageNo）来获取页面。首先查找缓存，没有的话就通过 Catalog 获取 DbFile 读取页面并加入缓存。如果缓存占满，就要进行页面置换（暂时不需要）。 1234567891011public Page getPage(TransactionId tid, PageId pid, Permissions perm) throws TransactionAbortedException, DbException &#123; Page res = idToPage.get(pid); if(res == null) &#123; Catalog catalog = Database.getCatalog(); DbFile f = catalog.getDatabaseFile(pid.getTableId()); res = f.readPage(pid); idToPage.put(pid, res); &#125; return res;&#125; Exercise 4 src/java/simpledb/storage/HeapPageId.java （继承自 PageId） src/java/simpledb/storage/RecordId.java src/java/simpledb/storage/HeapPage.java （继承自 Page） 前两个 Id 对象主要就是 hashcode() 和 equals() 方法的编写，注意： 在重写一个类的 equals 方法的时候，必须同时重写 hashCode 方法。否则的话，在使用需要判断 hash 值的数据结构（如 HashMap）进行存储时就会出现问题。要求： equals 为 true 时 hashCode 一定为 true；hashCode 为 true 时，equals 不一定为 true。 HeapPage 是实际存储在缓存中的页面（从硬盘读取到内存），它主要包含头部 header 标志位和一个固定长度的 tuple 数组（slots），结构示意图如下： image.png 页面中的 slot（插槽）有几个，header 就有几位，当一个元组插入 slot 后，header 对应位置设置为 1，删除元组则反之。在 SimpleDB 中，一个 table 的 TupleDesc 确定下来后，tuple 的长度就是固定的，因此可以计算出该页面可以有多少个 slot，用于初始化 header 和数组。 计算 slot 个数： 123456private int getNumTuples() &#123; // 每个页面可存储的元组数计算公式（大小单位是字节）： // 页面大小 * 8 / (元组大小 * 8 + 1)，向下取整 int numTuples = BufferPool.getPageSize()*8 / (td.getSize()*8+1); return numTuples;&#125; +1 是因为每个元组要附带一个标志位。 计算 header 大小（字节），多余的 0 位不考虑： 12345private int getHeaderSize() &#123; // Header要存储numSlots个bit，计算所需的bytes int headerSize = (int) Math.ceil(numSlots / 8.0); // 向上取整 return headerSize;&#125; HeapPage 在初始化时接受一个 pageId 和从硬盘读入的序列化后的 byte 数组进行反序列化，相反，getPageData 方法将该页面序列化以存入硬盘。 需要实现 isSlotUsed() 方法，该方法返回某个 slot 是否插入了元组。检查 header 对应位置的标志位是否为 1 即可。 12345public boolean isSlotUsed(int i) &#123; // 注意规定了从每个byte从右到左（low to high） byte slot = (byte) ((header[i/8] &gt;&gt; (i%8)) &amp; 1); return slot == (byte)1 ? true : false;&#125; Exercise 5 src/java/simpledb/storage/HeapFile.java （继承自 DbFile） HeapFile 对应一个表在硬盘中存储的文件，存储的单位是 HeapPage，所以主要是实现 readPage() 方法，它接受 pageId，需要找到对应 Page 在文件中的偏移量读取出来。一定要用文件随机读取，而不能一次性全部读到内存中，因为文件可能会很大。 12345678910111213141516public Page readPage(PageId pid) &#123; // 找到对应Page所在的偏移量，读取后生成HeapPage int pageSize = BufferPool.getPageSize(); int offset = pid.getPageNumber() * pageSize; byte[] data = new byte[pageSize]; Page heapPage = null; try (RandomAccessFile f = new RandomAccessFile(file, &quot;r&quot;)) &#123; f.seek(offset); f.read(data); heapPage = new HeapPage((HeapPageId)pid, data); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return heapPage;&#125; 另外的一个难点是实现 iterator() 方法，它的功能是遍历该表（DbFile）中的所有元组。那么就需要我们遍历 HeapFile 的所有 HeapPage，过程中使用 HeapPage 的 Iterator 来遍历元组。但是上面实现的 readPage() 方法是给 BufferPool 调用的，因为所有的页面读取都要经过缓存。所以我们需要调用 BufferPool 的 getPage() 方法来获取页面，从 pageNo = 0 开始累加，直到到达该文件所存储的页面数量的上限，是在 numPages() 里计算得到的（文件大小除以 PageSize）。 Exercise 6 src/java/simpledb/execution/SeqScan.java （实现 OpIterator） Operator 是执行计划的基本单位，最简单、最底层的一个 Operator 就是 SeqScan，按照存储顺序扫描某一个表的全部元组。 这里主要添加了表的别名 alias的概念，我们需要生成一个 tableAlias.filedName 形式的 TupleDesc 以供后续使用。 实现 OpIterator 接口的全部方法，主要是调用 HeapFile 里的 Iterator 的相应方法。","categories":[],"tags":[]},{"title":"RDD分区与并行计算","slug":"RDD分区与并行计算","date":"2023-04-05T13:48:33.003Z","updated":"2023-04-05T13:52:43.632Z","comments":true,"path":"2023/04/05/RDD分区与并行计算/","link":"","permalink":"https://zyrate.github.io/2023/04/05/RDD%E5%88%86%E5%8C%BA%E4%B8%8E%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/","excerpt":"分区应该是 Spark 中最基础、最核心的概念了，首先搞要清楚为什么要分区。不分区，分布式并行计算就无从谈起。其实哪怕不是分布式，就是如今在一台电脑上 8 个核心也都是标配了，如果把所有的计算任务全都交给一个核心处理便是对硬件资源的极度浪费，效率也十分低下。而要想不浪费，就要采用 并行计算 ，让每一个核心处理一部分任务。而不同的计算需要独立的上下文环境，这就引入了 分区 的概念。每个分区拥有自己的数据和计算函数，当所有的分区计算完毕后，再将它们的结果合并输出。","text":"分区应该是 Spark 中最基础、最核心的概念了，首先搞要清楚为什么要分区。不分区，分布式并行计算就无从谈起。其实哪怕不是分布式，就是如今在一台电脑上 8 个核心也都是标配了，如果把所有的计算任务全都交给一个核心处理便是对硬件资源的极度浪费，效率也十分低下。而要想不浪费，就要采用 并行计算 ，让每一个核心处理一部分任务。而不同的计算需要独立的上下文环境，这就引入了 分区 的概念。每个分区拥有自己的数据和计算函数，当所有的分区计算完毕后，再将它们的结果合并输出。 Spark RDD 在逻辑上实现了以上的分区概念。 第一，在 Spark 中几乎所有功能的数据操作都是以 RDD 为单位的（当然还有累加器和广播变量，但是它们都有固定的应用场景），所以它可以看做在 Spark 中的一个“万能数据集”，不论什么数据都能往里面放，不论在哪个场景都可以用，首先明确这一点（其实是为了打破初学者对它的陌生感）。 第二，所谓分区（Partition），简单来讲就是 RDD 在内部将数据分成的不同 切片 ，从不同的数据源读取数据会按照不同的方式进行切片，因此不同的数据源往往会对应不同类型的 RDD 实现类，而每个 RDD 实现都有一个独立的 Partition 实现类来处理数据。在 Partition 实现类中，会用不同的方法存储实实在在的数据。不过这里要搞清楚，RDD 是惰性计算的，只有在执行行动算子后，数据才会在各种不同的 RDD 分区中 计算、接收、传递 ，并不做停留。因此我的理解是，每个 RDD 分区调用它所 依赖的上一级 RDD 的对应的分区计算方法，获得新的分区数据，这本质是一个 链式调用 。这样行动算子会触发数据从读取到一步步计算的链式调用，最终获得计算结果，可以看做分区是固定的，数据一直在变化。 由上所知，在没有发生 Shuffle 的时候，分区数量不变，不同分区之间的计算是 平行的 ，互不干扰，谁快一点谁慢一点都无所谓，重点是它们在同时计算，这就是并行计算。而在遇到了像 groupByKey、orderBy 这样的需要打乱原有数据的方法，分区之间不可能再相安无事了，它们需要相互交换数据，即进行 Shuffle。Shuffle 操作需要数据 落盘 因此十分低效。而当发生 数据倾斜 时，Shuffle 又能够有效地保证计算的 负载均衡 。 第三，RDD 在逻辑上实现了分区，而在集群上实际的计算如何实现的呢？这就要提到 RDD 的任务执行单位：Job、Stage、Task。简单来说，Job 对应一个行动算子，它内部通过 RDD 谱系图 划分 Stage，通常是遇到一个 Shuffle 操作会生成一个新的 Stage。每个 Stage 根据 RDD 的分区数目生成 Task，一个 Task 对应一个分区。注意 Task 运行的结果是目标 RDD 的一个分区，而不是相反。前两个仍然是逻辑上的，真正可以运行的是 Task。Task 是在 Executor 上运行的，每一个物理节点可以起一个或多个 Executor。 所以最终的运行模型是：Driver 端（就是写 Spark 程序的地方）生成 SparkContext 作为和 Spark 框架连接的入口，它会进行 DAG 图构建、Stage 划分、Task 生成等一系列操作，这些操作是在一个节点完成的。而封装好的 Task 会发送给 Yarn 等调度器进行调度，可能会根据 “计算向数据移动” 等准则分发给不同的节点的 Executor，从而进行计算。 知识点： RDD 计算时（行动算子）在 一个分区 内是一个一个数据根据谱系图执行逻辑，即前面一个数据的逻辑全部执行完毕后才轮到下一个数据。分区内部的数据执行是 有序的 ，不同分区之间的数据执行是 无序的 。 MapPartitions 可以以分区为单位进行数据转换操作，但是会将整个分区的数据加载到内存中进行引用，容易出现内存溢出。 窄依赖： 如果新生成的 child RDD 中每个分区都依赖 parent RDD 中的一部分分区，那么这个分区依赖关系被称为 NarrowDependency。 宽依赖： 表示新生成的 child RDD 中的分区依赖 parent RDD 中的每个分区的一部分。","categories":[],"tags":[]},{"title":"数据可视化","slug":"数据可视化","date":"2023-04-03T10:01:20.959Z","updated":"2023-04-05T13:45:05.771Z","comments":true,"path":"2023/04/03/数据可视化/","link":"","permalink":"https://zyrate.github.io/2023/04/03/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/","excerpt":"生活中数据可视化无处不在，以前都会有意无意地进行过可视化的工作，但是通过专业化的分析和方法设计出的结果会更能达到可视化的目的，设计过程也会更加得心应手。另外数据可视化有时候并不只是数据的展现，还包含着数据的挖掘。比如看到一批数据，从不同的角度和考量进行可视化可能会从中挖掘出不同的信息。","text":"生活中数据可视化无处不在，以前都会有意无意地进行过可视化的工作，但是通过专业化的分析和方法设计出的结果会更能达到可视化的目的，设计过程也会更加得心应手。另外数据可视化有时候并不只是数据的展现，还包含着数据的挖掘。比如看到一批数据，从不同的角度和考量进行可视化可能会从中挖掘出不同的信息。 本文是北京大学袁晓如老师《数据可视化》课程的学习笔记链接：数据可视化 - 华文慕课 - 中文MOOC平台 (chinesemooc.org) 第 1 章概念 数据可视化就是把一些复杂的数据转化成人们能够直接看到并理解的图形或图像，有利于我们更快地识别特征，发现知识。基于计算机的可视化系统通过对数据的视觉表达形式来帮助人们更有效地完成特定任务。 不同的领域、不同的任务、不同的受众的可视化构型是不同的，要做合理、有效的选择。 要考虑计算限制、人类限制、显示限制 总结第一章讲述了可视化的概念、构型和案例，其中构型的选择非常重要，需要考虑不同的领域、任务、受众和限制因素，要在多对矛盾中进行权衡。 第 2 章数据类型 数据集类型 结构化数据：已知数据类型、语义 表格（Tables） 网络（Networks） 场（Fields） 空间/几何（Spatial/Geometry） 多维表（Multidimensional Table） 树形（Trees） 非结构化数据：没有预定的数据模型，如文字、视频、图像。需要转化为结构化数据（NPL、文本挖掘） 数据类型：数据项、链接、属性、位置、网格 属性类型：定类型、定序型、定量型。不同的属性需要用不同的通道表示。看到一个可视化就分析有什么属性，看到属性就要想是什么类型。 表达力和有效性：服从一致性和重要性排序原则，一致性是指，视觉变量和数据属性应该匹配。 2.7 的设计案例有启发意义。 总结这一章主要介绍了各类数据集合数据的类型，目的是强调在可视化过程中，对属性类型的分析是十分重要的，不同类型的属性需要考虑不同的可视化方法，这决定着最后的呈现效果（千差万别）。要培养分析数据属性的思维。 第 3 章数据编码（具体步骤） 符号和通道 符号标记（Marks）：如用圆点和直线代表数据项和连接 点、线、面，（包含、连接、嵌套） 视觉通道（Channels）：符号标记的表现形式，如圆点的颜色 分为以下两个类型，顺序代表有效性从高到低 &lt;定类型&gt; ：空间区域、颜色、运动模式、形状 &lt;定序定量型&gt; ：位置、长度、倾斜度、面积、深度、亮度/饱和度、弧度、体积 考虑视觉通道的五个属性：选择性、关联性、量化性、可序性、容量 史蒂文心理物理强度定律：强度由高到低：饱和度、长度、面积、深度、亮度，感官测试：The eyeballing game (woodgears.ca) 不同类别应该采取的通道排序：image.png 总结直观地感受了各类视觉通道的差异和优缺点，在可视化的时候首先要选择正确的符号和通道，让人们有对数据更加准确的感受。 第 4 章可视化任务与分析 分析三要素： 对象：判断第二章所述的数据类型和属性类型 手段：将第三章所述进行实践 目的：考虑用户需求（什么样的用户） 可视化任务抽象。不同的可视化有不同的任务，这里的任务（功能）是从用户的角度出发，用户为什么需要可视化，该可视化想要用户得到什么信息。要识别任务-数据组合，寻找可能的解决方案。即分析三要素中的目的（行动和对象），行动有以下三个层次（由高到低）：分析、搜索、查询。image.png image.png 分析三要素中的对象，对于不同的对象关心不同的特点： image.png 分析三要素中的手段，考虑可视化构型：视觉编码、交互。（后面讲） 可视化设计验证四层模型：image.png 所谓问题导向就是某个领域的某个问题需要可视化，这时四层模型从外到内进行工作。所谓技术导向就是某个新型的可视化技术出现了，从内到外去寻找可以可视化那些领域问题。 详细学习 4.5 可视化案例。 总结讲述了可视化过程中需要完成哪些分析工作，有哪些要素。从一个顶层抽象的角度阐述了可视化的整个流程。 第 5 章交互 视图操纵的方法 视图随时间变化 重新编码，对于对象 调整参数，不同的小控件（滑块、按钮等） 调整布局、顺序，What、How、Why 重排，对复杂的表格不同的维度（Table Lens）/ 平行坐标 调整对齐方式，堆叠柱形图 过渡动画，在两个状态间做插值平滑 视图分面（Facet） 并置视图（重要）：把两个图放在一起关联 image.png，动态查询是一个经典的例子，快速、增量式和可逆的交互操作。 分隔视图 image.png 叠加视图 image.png 数据约简（Reduce） 过滤：交叉过滤（一个维度变化，另外跟着变） 聚合：空间聚合 不完全互斥可视化系统：Jigsaw总结讲述了可视化中最有趣但却做复杂的交互操作，介绍了视图操纵的几种方法，通过例子体会到不同交互方法的特点和功能，恰当的交互能够给用户带来良好的体验的同时，也能够让用户有更多的发现。 第 6 章光与颜色 颜色表现不止于单一的颜色，还要考虑背景色，和周围的颜色（上下文）。 环境颜色会增加其自身的相反颜色以获得更强的对比 深色增加浅色 红色增加绿色 蓝色增加黄色 感知差异依赖于背景 颜色模型：《CIE 标准观测》 色度图 RGB 色度（三角形） 投影色域 对立色彩 颜色设计准则（经验） 需要考虑上下文，这里的上下文是指除颜色设计之外的各种对象与概念。（比如用户和预算等） 并不是五彩缤纷就是好的，好的设计让信息更吸引人。 颜色包括 &lt;色相、饱和度、亮度&gt; 三个属性，要精确区分。 控制明度，确保易读性 控制色相种类，定义颜色分组，避免太多颜色竞争而混乱，控制“弹出效应” 使用中和背景，最小化 “同时对比效应” 在不同的可视化场景，根据颜色标注的目标不同，颜色的选择也不同。比如飞机上的仪表盘属于需要快速反应的场景，颜色不能太多。 ColorBrewer: Color Advice for Maps (colorbrewer2.org) 网站提供不同的配色方案。 总结在使用颜色的时候需要考虑很多因素，比如对比、色盲等。在设计的时候需要遵循设计准则，让颜色起到增进理解而不是相反的作用。首先要理解颜色的各种属性，精确区分，谨慎选择。 第 7, 8 章表格表格分为平面表格（唯一索引）和多维表格（基于多个键的索引）。 平面数据 表格数据的比较 条形图（可以有不同方向）：要注意基准问题（起始值是否从 0 出发）；要注意是用线性变换还是对数变换，这里的变换是指纵轴单位长度的变化。 折线图：可用【光滑】【连接】和【散点】。要注意如果两个数据点之间连接起来，代表这个属性是可以插值的（比如年龄），如果属性不能插值（比如性别分类）则不能随意连接起来。 散点图：常常用于揭示两个维度之间的相关性。如果有第三维的话，可以将其映射到其他的视觉属性，比如颜色、大小；要注意不要过度绘制，要善用透明度和趋势线。 饼图/圈图：用于表示数据的组成。强调精确数值时用条形图，强调比例时用饼图。 堆叠条形图：将圈图拉直放到坐标系中，比饼图更加直观。 堆叠面积图：将离散的堆叠条形图连接起来。 表示数据的分布的图： 【直方图】与柱状图的区别是没有间隙，横轴是某个属性的区间划分；经验法则：根据数据量的平方根来确定划分区间的数目。 【密度图】 【箱型图】 【小提琴图】 【热力图】 表格可视化经典方法：Table Lens（表格透镜） 高维数据 散点图：点的位置表示两个属性，点的大小、颜色表示更多的属性，但往往表示不了高维（大于三个维度）。 散点矩阵图：每行/列是一个维度，每个单元格绘制两个维度的散点图。下图是 4 个维度两两之间的关系：image.png SPLOM 聚合-热力图：类似于散点图，减少计算量。image.png 相关热力图 Rolling the Dice：两个散点图无缝转换 平行坐标：将 x,y,z 等坐标轴平行放置，可以引入更多的维度，一条连线代表一个数据项，适用于异构数据。当数据量较大的时候，采用 &lt;增加透明度、捆绑、采样&gt; 来解决杂乱问题。 image.png 降维：保留尽可能多的变化，绘制低维空间，主成分分析。 多维缩放：让两两之间在平面的距离尽量正比于在高维空间的距离。常用于文本分析。 地形图表示。 维度嵌套/堆叠： 维度有限，工程数据分析常用 多方法耦合：平行坐标+散点图 其他方法：太多了，看 8.6 节 总结详细讲述了各种图对于表格数据可视化的作用，适当进行选取。 第 9, 10 章网络结构 层次结构（树）：用于有组织结构、分级分类的数据，有谱系树、进化树、搜索树、决策树。 显式树可视化 Reingold-Tilford 布局：类似思维导图 DOI 树（突出焦点）：树节点过多，只强调部分节点（增大），或用三角形代表不重要的子树。 双曲线树（突出焦点）：面向大规模的层次结构数据，全体数据可见，焦点放大。image.png 隐式树可视化：看不见树的结构，但是树的内部关系。较重要的是包含式非显式布局。其中最重要的是【树图】（Treemap）：切分空间，节点为长方形，节点面积代表相应属性。 树比较可视化：用柱状图进行树之间的比较。 图的可视化 两种主要类型的任务：【基于属性】、【基于拓扑】。 显式图形式：image.png，布局标准如下，减少用户阅读的干扰（不用全部满足）： 最小化边交叉 最小化相邻接点的距离 最小化绘图区域 边长度统一 最小化边弯曲 最大化不同边之间的角距离（过多的锐角不容易分辨） 宽高比约为 1（不太长也不太宽） 对称性（类似的图结构看起来相似） 矩阵形式：即图的邻接矩阵。非常适合邻域相关的任务，不适合路径相关的任务；节点的顺序很重要，排序后可能会发现规律。 混合显示与矩阵形式：NodeTrix。image.png 力导向布局算法：边=弹簧，点=互斥磁铁，算法开销较大 image.png 总结不同可视化方法之间需要进行取舍，为了相应的目的，可能会降低对另外一部分性能的支持。不同的可视化方法可以混用，可能达到更好的效果。 第 10 章时间序列时间序列数据就是其中一个变量是时间的数据，也可以说是高维中一个维度是时间的数据。vcg.informatik.uni-rostock.de可视化方法有： 缩略组图（Small Multiples）：在单个页面上显示的呈缩略图大小的图形集，表示单个现象的不同方面（不同时间）。也适用于多变量（多维）显示。比如新冠晴雨表。 形态替换：将时间视为隐藏的维度，为每个时间帧生成一个可视化，然后播放动画，用户可以进行追踪（可以加上轨迹）。Gapminder Tools 。但是该方法有一个问题是变化盲视，即人们没有注意到场景中可见元素的变化，需要根据具体情况解决（如增加视觉编码）。 时间序列图：将横坐标规定为时间，纵坐标为属性（可以有多个，不同编码也可以嵌套堆叠）。对于多个时间序列的比较，有以下几种方法： 简单线图：多条不同的线在一起。 编织线图：交替地根据数值的大小进行前后排列。 计算曲线焦点并垂直切割曲线面积，按照深度排序优先绘制最高部分面积。 换句话就是：高个子永远在后面。 image.png 缩略视图：见前文。 水平线图：解决缩略视图在高度较小的情况下空间利用问题。（压缩高度，保留精度） 堆叠线图：把不同的线型堆叠在一起。 螺旋图：更好的体现周期性；注意比例和标注。 像素驱动方法：每个像素代表一个时间点。 一行行/一列列排布 用填充曲线（Peano-Hilbert）：时间上相近的，空间上也相近。 时间曲线（Time Curves）：时间顺序的排列并不是规则的（水平的），而是根据内容相似性进行分布（弯曲）。曲线的形状可以表示相应的演变。（高维映射到低维 / 多维缩放） 主题河流（ThemeRivers）：表示文本随时间的变化。 从左到右流经时间，类似堆叠曲线图 image.png 总结时间在可视化里面可以看做高维中的一个带有先后顺序的属性，所以时间序列可视化都是在视觉上具有一定的连续性，这种联系可以让人们更直观地感受时间的流动与事物的变化。 第 12 章地图 使用地图的原则和任务 原则：当空间关系被着重强调时使用地图 任务：寻找地点/特征、寻找从 A 到 B 的路径、辨认与地点相关的属性、基于地点比较属性 地图投影 - 将地球展开 要考虑的属性：面积、形状、方向、方位、距离、尺度 投影方法 墨卡托投影：投影至一个包裹着地球的圆柱上，再展开成平面。所有的经纬线都是直线前垂直相交；方位准确，面积不准确。 方位角等距投影：确定航线走向。image.png 温格尔投影：最小化三种失真（面积、方向、距离）。image.png 锥形投影 阿尔博斯等面积投影：正确显示面积 复合投影 其他投影方式：Extended geographic projections for d3-geo. (github.com) 区域分布地图 用区域填充的颜色或图案来表示数值，如美国大选地图 问题：具有误导性，因为某区域面积的大小可能与数值没有关系 解决方法：同一个颜色用深浅区分数值大小，或加入其他编码（如密度） 等高线地图：用来表述在空间中的数值分布，特别是数值之间的过渡。 统计/变形地图：舍弃了地理区域的真实面积，而用数值大小来决定面积（缩放），但保留了原地理区域之间的方位、接壤等信息。 比例标识地图：保留原地理区域的真实面积，而采用添加圆圈（或其他图形），用它的的大小或其他定量属性来代表数值的大小。 流图：用于表示数据在不同地域之间的流动。（交通部门） 地铁地图：采用伦敦地铁图方式。线路水平、垂直或 45 度，车站间等距。 总结地图可视化都是以真实的地理区域为基础，而自然地理区域的面积、方位是固定的，想要表示的数据又往往与面积、方位无关，这就需要考虑如何规避掉区域自然属性对可视化目的的干扰。 第 13 章经验法则大多数情况下简单的、经验性的、探索性的但不是很准确的原则，体系不完整。 慎用 3D（但是技术在发展） 屏幕不是三维的，更适合 2D 信息 人对深度的判断不够精确 会产生遮挡，无法了解相关关系，带来时间成本 透视会引起失真 3D 下的文本会倾斜，造成认知负荷 慎用 2D：能用 1D 的列表就不要用 2D，1D 更适合查找、排序任务。在可视化里面，能简则简，不要追求复杂（越简洁越有效）。 慎用多视图的简单组合：缺乏数据内在逻辑的关联，无法提供深度探索。多视图需要有侧重点，图与图之间要紧密联系，有紧密的交互。（有机结合） 可见性重于记忆：如果能够通过不同视图直接对比，就不要采用动画，因为动画要求用户记忆，带来负担。 分辨率优先：沉浸感依赖于分辨率。简单说就是优先提高分辨率，而不是整花里胡哨的东西。 概览优先，缩放与过滤，细节按需呈现：【大量数据 -&gt; 展示概览，忽略细节 -&gt; 提供提示 -&gt; 用户定位到感兴趣的地方 -&gt; 放大 -&gt; 涌现细节】 交互响应不可缺少：即时反馈非常重要，如不能即时，应告知用户处理进度或先显示一部分。 黑白情况下的可用性：可视化在黑白情况下依然有效。借用亮度、色度、饱和度等通道。 功能重于形式：坚持有效性优先原则，考虑用户需求。 总结经验法则是贯穿于所有可视化技术的原则，在进行可视化工作之前和完成之后，都可以对照经验法则检验工作是否得当。","categories":[],"tags":[]}],"categories":[],"tags":[]}