[{"title":"MIT6.830 SimpleDB 实现笔记 Lab 6","path":"/2023/11/15/Lab 6/","content":"Lab 6 实现 SimpleDB 的基于日志系统的回滚（rollback）和恢复（recover）功能。 WAL 机制首先，SimpleDB 要实现的是预写式日志（Write-ahead logging, WAL），也就是所有修改在生效之前都要先写入 log 文件中，写入的内容包括 redo 和 undo 信息，分别保证事务的持久性和原子性。 在 SimpleDB 中，日志的单位和锁一样是页面，每个页面都可以通过 setBeforeImage 方法来设置 oldData，也就是每次 flush 到磁盘前页面还未变动时的旧数据（是上一次 flush 的时候保存的）。日志系统会在每次 flush 脏页的时候把 beforeImage 和 afterImage 写入日志文件，分别代表旧数据和新数据。这样在需要 redo 的时候，就把 afterImage 写入磁盘；需要 undo 的时候，就把 beforeImage 写入磁盘。 Lab 6 只要求实现 LogFile 类中的 rollback 和 recover 方法： 前者用在事务 abort 的时候，需要撤销 (undo) 该事务的所有操作，回滚数据库到之前的状态； 后者用在发生崩溃 crash 的时候，需要撤销 (undo) 所有未提交事务的所有操作、重做 (redo) 所有已提交事务的所有操作，恢复数据库到正常状态。 缓冲区管理策略数据库的缓冲区管理策略有两类四种，分别是： steal 策略允许从页面缓存逐出“脏页”。此时磁盘上可能包含 uncommitted 的数据，因此系统需要记录 undo log，以在事务 abort 时进行回滚（rollback）。 no-steal 策略不允许从页面缓存逐出“脏页”。表示磁盘上不会存在 uncommitted 数据，因此无需回滚操作，也就无需记录 undo log。 force 策略事务在 committed 的时候必须将所有更新立刻持久化到磁盘，这样的话不需要 redo log，因为只要日志中存在 commit 记录就说明磁盘已经更新了全部数据。但是这样会导致磁盘发生很多小的写操作（更可能是随机写）。 no-force 策略事务在 committed 之后可以不立即持久化到磁盘，这样可以缓存很多的脏页批量持久化到磁盘，这样可以降低磁盘操作次数（提升顺序写），但是如果 committed 之后发生crash，那么此时已经提交的事务数据将会丢失（因为还没有持久化到磁盘），因此系统需要记录 redo log，在系统重启时候进行回复（recover）操作。 在 SimpleDB 中, 之前的 Lab 要求实现的是 no-steal 和 force 策略，但是这种策略的效率不高。所以在本次 Lab 的 LogTest 中，它会时不时的打破 no-steal 策略，也就是通过随时调用 flushAllPages() 让磁盘上存在未提交的数据，测试 abort 后的回滚操作。同时也默认 no-force 的存在（虽然实际不是），以测试 crash 后的恢复操作。所以我们 redo 和 undo 都需要实现。 日志文件结构Log File 中一条记录的格式是：&lt;RECORD_TYPE:int | TID:long | content | start:long&gt; 其中 RECORD_TYPE 指记录的类型，TID 指事务的标识，content 在不同的类型中表示不同内容， start 指此条记录开始位置的偏移量。 RECORD_TYPE 总共有 5 种表示不同的行为： BEGIN, 事务开始 UPDATE, 事务对页面进行 UPDATE 操作 COMMIT, 事务提交 ABORT, 事务中断 CHECKPOINT, 检查点 在运行过程中各类记录被不停地追加到 Log File 里面。 由于多个事务之间时并行执行的，所以日志文件里不同事务对不同页面的各项操作是混合交叉在一起的。 BEGIN、COMMIT 和 ABORT 这三种记录的 content 位置是空的，不存储数据；而 UPDATE 存储的是序列化后的 beforeImage 和 afterImage；CHECKPOINT 存储的首先是一个 INT 类型代表当前活跃事务（未提交）的数量，后面跟的是每个活跃事务的 TID 和 BEGIN 记录的位置 offset（都是 Long 类型）。 检查点是为了加快恢复过程的速度。如果没有检查点，那么系统在宕机重启后需要从头对 Log File 进行顺序访问，依次找到所有未提交和已提交的事务进行 undo 和 redo 操作，费时费力。而检查点机制要求在向 Log File 中添加 CHECKPOINT 的时候，将缓冲区中所有的脏页刷新到磁盘，也就代表着在检查点之前提交了的事务无需在重启后执行恢复操作，因为磁盘已经拥有这些事务更新后的数据。我们只需从检查点之后顺序访问 Log File 即可。 另外需要注意的是，检查点会记录那个时刻还未提交的所有事务 ID，这些事务并不能保证宕机后的原子性和持久性，因此也需要对这些事务进行恢复操作。 Rollback 实现rollback 方法在事务被 abort 的时候调用，此时该事务对所有页面产生的所有修改都应该失效，也就是说需要将所有相关页面的 beforeImage（旧数据）恢复到磁盘上（undo）。 123456789101112131415161718192021222324252627282930313233343536373839public void rollback(TransactionId tid)&#123;//省略synchronized结构\tpreAppend(); // 找到该事务在file中的第一个记录的偏移量 long offset = tidToFirstLogRecord.get(tid.getId()); raf.seek(offset); // 顺序访问直到文件末尾\twhile (true) &#123; try &#123; int type = raf.readInt(); // 记录类型 long record_tid = raf.readLong(); // TID switch (type) &#123; case UPDATE_RECORD: // 更新记录 Page before = readPageData(raf); // 旧数据 Page after = readPageData(raf); // 新数据 if(record_tid == tid.getId())&#123; // 先把此页面从缓存中去除 Database.getBufferPool().discardPage(before.getId()); // 然后把旧数据写入Table文件 Database.getCatalog().getDatabaseFile(before.getId().getTableId()).writePage(before); &#125; break; case CHECKPOINT_RECORD: // 跳过所有检查点记录 int numXactions = raf.readInt(); while (numXactions-- &gt; 0) &#123; long xid = raf.readLong(); long xoffset = raf.readLong(); &#125; break; &#125; raf.readLong(); // 跳过start指针 &#125; catch (EOFException e) &#123; break; &#125; &#125;&#125; Recover 实现recover 方法在数据库 crash 重启后调用，需要将检查点（如果有的话）中及其之后的所有事务进行恢复操作，未提交的 undo，已提交的 redo。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public void recover() throws IOException &#123;// 省略synchronized结构\trecoveryUndecided = false; /* redo就是写入afterimage，undo就是写入beforeimage */ // 已提交的事务ID集合\tSet&lt;Long&gt; commitedIds = new HashSet&lt;&gt;(); // 检查点存储的活跃事务集合\tMap&lt;Long, Long&gt; activeTxns = new HashMap&lt;&gt;(); // 从检查点往后所有事务的集合（所有的旧页面和新页面） Map&lt;Long, List&lt;Page&gt;&gt; beforePages = new HashMap&lt;&gt;(); Map&lt;Long, List&lt;Page&gt;&gt; afterPages = new HashMap&lt;&gt;(); long cpOffset = raf.readLong(); // 检查点位置 if(cpOffset != -1)&#123; raf.seek(cpOffset); // 如果有检查点，直接从此处开始\t&#125; // 顺序访问直到文件末尾\twhile (true) &#123; try &#123; int type = raf.readInt(); // 记录类型 long record_tid = raf.readLong(); // TID switch (type) &#123; case UPDATE_RECORD: Page before = readPageData(raf); // 旧数据 Page after = readPageData(raf); // 新数据 beforePages.computeIfAbsent(record_tid, k-&gt;new ArrayList&lt;&gt;()).add(before); afterPages.computeIfAbsent(record_tid, k-&gt;new ArrayList&lt;&gt;()).add(after); break; case CHECKPOINT_RECORD: int numXactions = raf.readInt(); while (numXactions-- &gt; 0) &#123; long xid = raf.readLong(); long xoffset = raf.readLong(); activeTxns.put(xid, xoffset); // 记录活跃事务 &#125; break; case COMMIT_RECORD: commitedIds.add(record_tid); // 记录已提交事务 break; &#125; raf.readLong(); // 跳过start指针 &#125; catch (EOFException e) &#123; break; &#125; &#125; /* 注意undo和redo的顺序不能乱，否则redo被undo覆盖 */ // undo未commit的 for(Long record_id : beforePages.keySet())&#123; if(!commitedIds.contains(record_id))&#123; List&lt;Page&gt; befores = beforePages.getOrDefault(record_id, new ArrayList&lt;&gt;()); for(Page page : befores)&#123; Database.getCatalog().getDatabaseFile(page.getId().getTableId()).writePage(page); &#125; &#125; &#125; // redo已经commit的 for(Long record_tid : commitedIds)&#123; List&lt;Page&gt; afters = afterPages.getOrDefault(record_tid, new ArrayList&lt;&gt;()); for(Page page : afters)&#123; Database.getCatalog().getDatabaseFile(page.getId().getTableId()).writePage(page); &#125; &#125; // 处理在checkpoint之前开始但是在checkpoint还未提交的事务 for(Map.Entry&lt;Long,Long&gt; entry : activeTxns.entrySet())&#123; long active_id = entry.getKey(); long active_offset = entry.getValue(); boolean commited = commitedIds.contains(active_id); raf.seek(active_offset); // 代码与上文类似 while (true) &#123; try &#123; int type = raf.readInt(); long record_tid = raf.readLong(); switch (type) &#123; case UPDATE_RECORD: Page before = readPageData(raf); Page after = readPageData(raf); if(commited)&#123; // redo Database.getCatalog().getDatabaseFile(after.getId().getTableId()).writePage(after); &#125;else&#123; // undo Database.getCatalog().getDatabaseFile(before.getId().getTableId()).writePage(before); &#125; break; case CHECKPOINT_RECORD: int numXactions = raf.readInt(); while (numXactions-- &gt; 0) &#123; long xid = raf.readLong(); long xoffset = raf.readLong(); &#125; break; &#125; raf.readLong(); &#125; catch (EOFException e) &#123; break; &#125; &#125; &#125;&#125; 需要注意 undo 和 redo 的顺序不能颠倒，否则会出现数据覆盖问题。 image.png"},{"title":"MIT6.830 SimpleDB 实现笔记 Lab 5","path":"/2023/11/07/Lab 5/","content":"Lab 5 要求实现 SimpleDB 的 B+树索引存储机制。整体的 B+树相关代码还是较为复杂的，但是 SimpleDB 帮我们写了大部分结构性的代码，让我们去完成较重要的功能性代码。但是所有的代码都需要理解透彻。 B+树索引结构首先，在 InnoDB 引擎中，B+树索引分为主索引和辅助索引，主索引的叶子结点记录着完整的数据，而辅助索引的叶子结点只记录着主键的值，在查找时需要先插找到主键值，再到主索引中进行查找，相当于二级索引机制。但在 SimpleDB 中，只要求实现主索引。 一个关于索引的定义：索引就是一个表属性子集的副本，为了通过这些属性更高效的访问数据而进行了一定的组织和排序，数据库需要确保表和索引是逻辑同步的。这里可以理解成，B+树的非叶结点就是上述的“属性子集的副本”，是真正的索引结构，而叶结点并不是副本，是表的属性数据集合本身。 也就是说，在 SimpleDB 中一个表可以用 B+树 File 形式存储，也可以用 HeapFile 形式存储，这两者之前是平行关系，取决于用户的选择，它们拥有相同的存储方式和顶层抽象。 对于 HeapFile，它继承自 DbFile，内部存储 HeapPage，通过 BufferPool 访问； 对于 BTreeFile，它同样继承自 DbFile，内部存储 BTreePage，也通过 BufferPool 访问，缓存和锁管理机制是通用的。 但是由于 B+树结构复杂，因此有多种不同类型的 BTreePage，分别是：BTreeRootPtrPage、BTreeHeaderPage、BTreeInternalPage、BTreeLeafPage。但其实，与 B+树的逻辑结构相关的只有最后两种，分别对应内部结点和叶子结点。B+树逻辑结构 而 BTreeHeaderPage 的作用是记录当前 BTreeFile 中还有没有空页（由于从 B+树删除结点并不会在物理层面也删除，有点像静态哈希表），如果有空页那么新建结点的时候就可以复用该页，如果没有就新建一个空页到 BTreeFile 中去。 BTreeRootPtrPage 的作用是记录根结点（internal 或 leaf）的在 File 中的位置，因为在进行一系列的插入、删除操作后，File 中的 Page 是无序存储的，B+树逻辑结构靠的是地址链接，所以 File 的第一个 Page 不一定是根结点，所以需要记录。BTreeRootPtrPage 中有一个静态方法 getId()，可以看到新建了一个 pageNo=0 的 PageId，所以这个页面永远储存在 File 的第一个位置。 在做此 Lab 的时候，不用想着在一开始搞懂所有类的所有方法，容易没有头绪。就从 Lab 要求补充的代码处入手，需要用什么结构、方法、接口就去了解什么，很容易就上手了。 BTreeLeafPage 存储着该叶子结点上的所有 Tuple 和左右兄弟指针，调用 iterator() 可以依次（正向或逆向）遍历 Tuple。 BTreeInternalPage 存储着所有的key值和指向孩子节点的指针，调用 iterator() 可以一次（正向或逆向）遍历 BTreeEntry，其中包含“key、左指针、右指针”。这个实体只是为了传递数据，修改里面的值并不会对结点本身造成影响，如果想更新结点数据，需要调用 updateEntry() 方法。 所有的“指针”都是指页面的 PageNo，类型是 int。 B+树的查找核心思想： 对于一个目标值 f，从根结点开始查找，遍历该结点所有的 key 值，如果 f&lt;=key ，那么进入这个 key 的左孩子递归查找；如果遍历到了最后一个 key 仍不符合条件，那么进入右孩子递归查找。直到遇到叶子结点，直接返回此结点，因为它一定包含 f（或 f 不在 B+树中）。 123456789101112131415161718192021222324private BTreeLeafPage findLeafPage(TransactionId tid, Map&lt;PageId, Page&gt; dirtypages, BTreePageId pid, Permissions perm, Field f) throws DbException, TransactionAbortedException &#123; if(pid.pgcateg() == BTreePageId.INTERNAL)&#123; // 非叶结点 // 从BufferPool拿到指定pid的非叶页面 BTreeInternalPage inPage = (BTreeInternalPage) getPage(tid, dirtypages, pid, Permissions.READ_ONLY); Iterator&lt;BTreeEntry&gt; iterator = inPage.iterator(); // 遍历该页面的所有key，和目标f作比较（见B+树的查找） while(iterator.hasNext())&#123; BTreeEntry entry = iterator.next(); if(f==null||f.compare(Op.LESS_THAN_OR_EQ, entry.getKey()))&#123; // 目标值为null或小于等于key值，进入左孩子递归 return findLeafPage(tid, dirtypages, entry.getLeftChild(), perm, f); &#125; if(!iterator.hasNext())&#123; // 遍历到最后一个，进入右孩子递归 return findLeafPage(tid, dirtypages, entry.getRightChild(), perm, f); &#125; &#125; &#125;else if(pid.pgcateg() == BTreePageId.LEAF)&#123; // 叶子结点，直接返回指定pid的叶子页面 return (BTreeLeafPage) getPage(tid, dirtypages, pid, perm); &#125; return null; &#125; getPage() 方法里面调用了 BufferPool 的 getPage 方法，保证了锁机制的正常执行，另外它接受并维护一个 dirtypages 映射，每当访问类型是 READ_WRITE 的时候就将该页面设为 dirty，以便记录脏页集合。 B+树的插入利用 B+树的查找代码，找到需要插入的元组应该在的叶子结点，直接插入。如果该结点已经满了，没有空位可以插入了，则需要进行分裂，分裂的过程可能会递归向上。 叶子结点的分裂： 找到中间 Tuple 位置，将该 Tuple 及其右侧的所有 Tuple 依次移动到一个新的 LeafPage 上，之后将这个中间 Tuple 的 key 值插入到父结点中，最后更新所有相关的指针。 叶结点的分裂 内部结点的分裂： 找到中间 key 位置，将该 key 右侧的所有 key 依次移动到一个新的 InternalPage 上，之后将这个 key 从原 Page 删除，插入到父节点中。 内部结点的分裂 两类分裂的区别在于，叶子结点分裂需要将中间 Tuple 的 key 复制到父结点中，而内部结点的分裂是将中间 key上移到父结点中，并且需要更新新页面所有子页面的父指针（因为这些子页面的父指针都指向原来的页面）。 在分裂的时候，需要向父页面插入值，此时父页面也可能会出现无空位的情况，递归处理即可。 叶结点的分裂代码： 1234567891011121314151617181920212223242526272829303132333435363738394041public BTreeLeafPage splitLeafPage(TransactionId tid, Map&lt;PageId, Page&gt; dirtypages, BTreeLeafPage page, Field field) throws DbException, IOException, TransactionAbortedException &#123; // 分裂位置 int splitFrom = page.getNumTuples() / 2; // 新叶子结点 BTreeLeafPage newLeaf = (BTreeLeafPage) getEmptyPage(tid, dirtypages, BTreePageId.LEAF); Iterator&lt;Tuple&gt; iterator = page.reverseIterator(); Field middleKey = null; // 中间Key // 逆序遍历旧叶子结点进行元组移动 for(int i=page.getNumTuples()-1; iterator.hasNext() &amp;&amp; i&gt;=splitFrom; i--)&#123; Tuple t = iterator.next(); page.deleteTuple(t); newLeaf.insertTuple(t); if(i == splitFrom)&#123; middleKey = t.getField(keyField); &#125; &#125; // 左右兄弟连接 BTreePageId rightSiblingId = page.getRightSiblingId(); newLeaf.setLeftSiblingId(page.getId()); newLeaf.setRightSiblingId(page.getRightSiblingId()); page.setRightSiblingId(newLeaf.getId()); if(rightSiblingId != null)&#123; // 不要忘了这一步的指针更新 BTreeLeafPage rightSibling = (BTreeLeafPage) getPage(tid, dirtypages, rightSiblingId, Permissions.READ_WRITE); rightSibling.setLeftSiblingId(newLeaf.getId()); &#125; /* key上移 */ BTreeEntry bTreeEntry = new BTreeEntry(middleKey, page.getId(), newLeaf.getId()); // 这个提供的方法里面有向上递归的部分 BTreeInternalPage parent = getParentWithEmptySlots(tid, dirtypages, page.getParentId(), field); parent.insertEntry(bTreeEntry); page.setParentId(parent.getId()); newLeaf.setParentId(parent.getId()); // 要插入的Key如果小于middle key，返回左（旧）叶子 if(field.compare(Op.LESS_THAN, middleKey))&#123; return page; &#125; // 否则返回右（新）叶子 return newLeaf; &#125; 内部结点分裂代码： 1234567891011121314151617181920212223242526272829303132public BTreeInternalPage splitInternalPage(TransactionId tid, Map&lt;PageId, Page&gt; dirtypages, BTreeInternalPage page, Field field) throws DbException, IOException, TransactionAbortedException &#123; // 新非叶结点 BTreeInternalPage newInternal = (BTreeInternalPage) getEmptyPage(tid, dirtypages, BTreePageId.INTERNAL); Iterator&lt;BTreeEntry&gt; iterator = page.reverseIterator(); BTreeEntry middleEntry = null; // 中间entry // 遍历旧非叶结点进行元组移动 for(int i=page.getNumEntries()-1; iterator.hasNext() &amp;&amp; i&gt;=splitFrom; i--)&#123; BTreeEntry e = iterator.next(); page.deleteKeyAndRightChild(e); if(i == splitFrom)&#123; middleEntry = e; break; &#125; newInternal.insertEntry(e); &#125; // 这个提供的方法里面有向上递归的部分 BTreeInternalPage parent = getParentWithEmptySlots(tid, dirtypages, page.getParentId(), field); middleEntry.setLeftChild(page.getId()); middleEntry.setRightChild(newInternal.getId()); parent.insertEntry(middleEntry); page.setParentId(parent.getId()); newInternal.setParentId(parent.getId()); // 更新新结点所有子页面的父指针 updateParentPointers(tid, dirtypages, newInternal); // 要插入的Key如果小于middle key，返回左（旧）非叶 if(field.compare(Op.LESS_THAN, middleEntry.getKey()))&#123; return page; &#125; // 否则返回右（新）非叶 return newInternal; &#125; B+树的删除B+树的删除有三种情况： 找到对应的叶子结点，删除 Tuple； 如果删除后该叶子结点的元组数小于 half full，且兄弟结点大于 half full，那么就从兄弟结点STEAL一些元组，以保持平衡； 如果兄弟结点已经是 half full 了，那么就合并这两个结点。两类结点的STEAL过程 在合并叶子结点的时候，会从父结点删除一个 key，因此需要递归向上判断。 注意在 STEAL 的时候，叶子结点是在转移完兄弟结点的 Tuple 后，根据情况把对应的 key 值复制到父结点，而内部结点则是移动到父结点。 在合并的时候，叶子结点是合并以后，父结点的对应 key 直接删除；而内部结点是将父结点对应 key 下移到对应位置。两类结点的合并过程 叶子结点的 STEAL 操作代码： 123456789101112131415161718192021public void stealFromLeafPage(BTreeLeafPage page, BTreeLeafPage sibling, BTreeInternalPage parent, BTreeEntry entry, boolean isRightSibling) throws DbException &#123; // 需要偷取的个数 int numToMove = (sibling.getNumTuples() - halfFull) / 2; Iterator&lt;Tuple&gt; iterator; if(isRightSibling)&#123; // 从左右不同结点偷取的顺序相反 iterator = sibling.iterator(); &#125;else&#123; iterator = sibling.reverseIterator(); &#125; // steal for(int i=0; i&lt;numToMove &amp;&amp; iterator.hasNext(); i++)&#123; Tuple t = iterator.next(); sibling.deleteTuple(t); page.insertTuple(t); &#125; // 如果从左边偷的，本页第一个key上替；如果从右边偷的，右边第一个key上替 Field key = isRightSibling ? sibling.iterator().next().getField(keyField) : page.iterator().next().getField(keyField); entry.setKey(key); parent.updateEntry(entry); &#125; 从左侧内部结点 STEAL 操作代码（右侧同理）： 1234567891011121314151617181920212223242526public void stealFromLeftInternalPage(TransactionId tid, Map&lt;PageId, Page&gt; dirtypages, BTreeInternalPage page, BTreeInternalPage leftSibling, BTreeInternalPage parent, BTreeEntry parentEntry) throws DbException, TransactionAbortedException &#123; // 偷取个数 int numToMove = (leftSibling.getNumEntries() - halfFull) / 2; Iterator&lt;BTreeEntry&gt; iterator = leftSibling.reverseIterator(); RecordId parentRecordId = parentEntry.getRecordId(); for(int i=0; i&lt;numToMove &amp;&amp; iterator.hasNext(); i++)&#123; BTreeEntry e = iterator.next(); leftSibling.deleteKeyAndRightChild(e); if(i == 0)&#123; // 开始的时候首先把父Entry旋转下来 parentEntry.setLeftChild(e.getRightChild()); parentEntry.setRightChild(page.iterator().next().getLeftChild()); page.insertEntry(parentEntry); &#125;else if(i == numToMove-1)&#123; // 到最后一个再把Entry旋转到父Entry的位置 e.setLeftChild(leftSibling.getId()); e.setRightChild(page.getId()); e.setRecordId(parentRecordId); // 必须要提前记录父Entry的RecordId，不然无法更新 parent.updateEntry(e); break; &#125; page.insertEntry(e); &#125; // 更新两个非叶Page的子Page的父指针 updateParentPointers(tid, dirtypages, page); updateParentPointers(tid, dirtypages, leftSibling); &#125; Merge 叶子结点代码： 1234567891011121314151617181920public void mergeLeafPages(TransactionId tid, Map&lt;PageId, Page&gt; dirtypages, BTreeLeafPage leftPage, BTreeLeafPage rightPage, BTreeInternalPage parent, BTreeEntry parentEntry) throws DbException, IOException, TransactionAbortedException &#123; while(iterator.hasNext())&#123; Tuple t = iterator.next(); rightPage.deleteTuple(t); leftPage.insertTuple(t); &#125; // 更新指针 BTreePageId rightSibling = rightPage.getRightSiblingId(); leftPage.setRightSiblingId(rightSibling); if(rightSibling != null)&#123; BTreeLeafPage rightSiblingPage = (BTreeLeafPage) getPage(tid, dirtypages, rightSibling, Permissions.READ_WRITE); rightSiblingPage.setLeftSiblingId(leftPage.getId()); &#125; // 删除父页面的Entry - 包含向上递归 deleteParentEntry(tid, dirtypages, leftPage, parent, parentEntry); // 清空右页面 setEmptyPage(tid, dirtypages, rightPage.getId().getPageNumber()); &#125; Merge 内部结点代码： 12345678910111213141516171819public void mergeInternalPages(TransactionId tid, Map&lt;PageId, Page&gt; dirtypages, BTreeInternalPage leftPage, BTreeInternalPage rightPage, BTreeInternalPage parent, BTreeEntry parentEntry) throws DbException, IOException, TransactionAbortedException &#123; // 删除父页面的Entry - 包含向上递归 deleteParentEntry(tid, dirtypages, leftPage, parent, parentEntry); // 父Entry先插下来 parentEntry.setLeftChild(leftPage.reverseIterator().next().getRightChild()); parentEntry.setRightChild(rightPage.iterator().next().getLeftChild()); leftPage.insertEntry(parentEntry); // 右全部移动到左 while(iterator.hasNext())&#123; BTreeEntry e = iterator.next(); rightPage.deleteKeyAndLeftChild(e); leftPage.insertEntry(e); &#125; // 清空右页面 setEmptyPage(tid, dirtypages, rightPage.getId().getPageNumber()); // 更新左页面子页面的父指针 updateParentPointers(tid, dirtypages, leftPage); &#125; Bug 记录 注意左子树的 key 小于等于当前结点的 key，如果漏掉等于的话在查找重复值的情况会出错。 不论是对 Tuple 还是 Entry，都要先 delete 再 insert，因为 insert 操作会更新 RecordId，如果此时 delete 的话会报错。 全部做完之后发现部分代码无法通过 checkRep()。 一个 BUG 是在 MergeLeafPages 的时候忘了更新右页面的左指针（需要 getPage） 另一个 BUG 是在 stealFromRightInternalPage 的时候没想到只移动一个 Entry 的情况，这个时候两个条件不能是 if-else if 的关系，而应该是并列的。 还有一个 BUG 是在 splitLeafPage 的时候同样忘记更新右页面的左指针。 在执行 BTreeTest 的时候，虽然通过了，但一直在报 ConcurrentModificationException 错（从死锁检测抛出），推测是 adjList 里面的 List 不是线程安全的，归根结底是 PageLock 的 holds 没有采用 CopyOnWriteArrayList，更改后消除报错。 image.png"},{"title":"MIT6.830 SimpleDB 实现笔记 Lab 4","path":"/2023/10/25/Lab 4/","content":"Lab4 是实现 SimpleDB 的并发事务系统，跟前面的内容相比较为复杂。 一般来说数据库的事务需要满足 ACID 特性，即原子性、一致性、隔离性、持久性。原子性就是该事务的所有操作要么全部完成，要么全部取消，要求通过下面的操作保证： 不从页面缓存中逐出“脏页”（被某个事务更新的页面）。——NO STEAL 规则 在事务正确提交时，强制刷新所有脏页到磁盘。 隔离性就是同时执行的多个事务不会相互干扰，通过将要实现的锁机制保证。一致性在 SimpleDB 中没有强调，持久性应该在 Lab6 的恢复功能上体现。 SimpleDB 事务并发控制实现锁机制在数据库中锁定对象可以是表、页面、元组、属性等，SimpleDB 规定的锁定粒度是页面（Page）。可供事务获取的锁类型有两种：共享锁和排他锁，规则如下。 事务在读取页面之前，必须具有共享锁； 事务在修改页面之前，必须具有排他锁； 多个事务可以在一个页面上具有共享锁； 只有一个事务可以在一个对象有排他锁。 在该规则下，如果一个事务在请求页面的时候，无法获取该页面的锁，就必须被阻塞，以等待锁资源被其他事务释放留给自己去竞争。特别的是，如果一个事物在申请排他锁时，如果已经持有了该页面的共享锁且是唯一一个持有者，那么可将此共享锁升级为排他锁（锁升级）。 两阶段锁（2PL）考虑两个事务按照上述锁机制正常执行，有可能发生下图的情况：（X 排他，S 共享）T1 和 T2 都正常提交了，但是 T1 对于页面 A 发生了“不可重复读”现象，即在同一个事务先后两次读到的数据有可能不一样（被别的事务如 T2 修改了）。 解决这个问题的办法就是实现两阶段锁协议（2PL）。2PL 的两个阶段分别是扩展阶段（Growing） 和 收缩阶段（Shrinking），在扩展阶段事务只能获取锁，在收缩阶段事务只能释放锁。 两阶段锁协议本身足以保证冲突可串行性，但它可能会导致级联中止（Cascading aborts） 问题，即一个事务的中止可能导致其他多个事务也一起中止。这是因为在 2PL 中一个事务可能基于另一个事务尚未提交的数据进行操作，如果那个事务被中止，就会发生级联中止。如下图：为了避免这种情况，需要实现严格两阶段锁协议（Strict 2PL），即一个事务只能在它提交或中止时释放所有锁。SimpleDB 要求实现 Strict 2PL 协议。这其实简化了操作，因为在赋予事务锁的时候不用考虑什么时候执行完了操作该释放，而是通通等到最后 commit 时释放。 页面级锁机制实现刚开始时看到需要实现读写锁，自然会想到 JUC 中的 ReentrantReadWriteLock 类，然而该类是负责线程同步的，一个事务可以有多个线程，所以他们不在同一粒度。另外只用 Java 提供的这些类并不能很好地实现 2PL 协议，也并不契合事务并发场景。因此我们需要自己实现事务的读写锁机制，但是类库中的一些思想可以借鉴。 我们定义一个 LockManger 来负责维护事务和锁的状态，在 BufferPool 中事务只需调用相应的方法来获取和释放锁就行了。可以想到 LockManger 需要提供以下方法： 12345678// 获取共享锁void acquireSharedLock(TransactionId tid, PageId pid);// 获取排他锁void acquireExclusiveLock(TransactionId tid, PageId pid);// 释放锁void releaseLock(TransactionId tid, PageId pid);// 是否持有锁boolean holdsLock(TransactionId tid, PageId pid) 更新后的 BufferPool.getPage 方法如下（因为是页面级锁定，所以只在这里获取锁）： 123456789101112131415&#123; if(perm == Permissions.READ_ONLY)&#123; // 获取共享锁 if(!holdsLock(tid, pid)) &#123; lockManager.acquireSharedLock(tid, pid); &#125; &#125;else&#123; // 获取排他锁 - 存在锁升级情况，所以不判断holdsLock lockManager.acquireExclusiveLock(tid, pid); &#125; ... //缓存中获取页面 ... return page;&#125; 所谓事务获取到锁就是“放行”，获取不到就是“阻塞”。 这里的“锁”其实说成“锁的使用权”或“钥匙”更贴切一点。每个页面其实只有一把锁，需要钥匙才能进入访问。而共享锁，就是说这把锁可以有多把钥匙开启，每一把钥匙给一个事务；排他锁就是只能有一把钥匙给唯一的事务。如果事务获取不到钥匙就被阻塞。其实 Java 中的重量级锁也是这个道理，有时候会被“锁”这个名词给绕晕。 LockManger 的作用就是记录谁拥有某个页面的钥匙，是把什么样的钥匙，为了统一起见，下文仍称“锁”。 接下来是 LockManger 的实现，既然每个页面只有一把锁，并且需要维护这把锁的状态和与事务的关系，那么就可以设计一个 PageLock 类来管理： 12345678910111213141516class PageLock&#123; private PageId pageId; // 页面ID private int lockState; // 0:空闲,-1:排他锁,&gt;0:获取到共享锁的事务数量 CopyOnWriteArrayList&lt;TransactionId&gt; holds; // 获取锁到的事务 public PageLock(PageId pageId)&#123; this.pageId = pageId; holds = new CopyOnWriteArrayList&lt;&gt;(); &#125; // 避免并发修改 public synchronized void stateIncrement(int n)&#123; lockState += n; &#125; public synchronized int getLockState()&#123; return lockState; &#125;&#125; 用一个 lockState 记录这个页面锁的状态。等于 0 代表该页面是空闲的，没有事务访问（无人持锁）；等于 -1 代表该页面的锁为排他锁；大于 0 代表该页面的锁为共享锁，具体数字表示有多少事务正在共享该锁。holds 记录了都是哪些（个）事务获取到该锁。 在 LockManger 中，我们用一个 Map 记录页面和锁的对应关系；为了方便查询，同样用一个 Map 记录事务和其所持有的锁集合的对应关系： 12private Map&lt;PageId, PageLock&gt; pageLocks;private Map&lt;TransactionId, List&lt;PageId&gt;&gt; lookups; 在实现“阻塞”效果时，采用了 wait/notify 的方式，也可采用 JUC 中的各种合适的工具类。注意如果仅仅是为了实现读写锁的话，不需要我们自己记录哪些事务陷入了等待，因为这些工具内部已经实现了记录阻塞线程的逻辑，可以在需要时唤醒。但是在后面实现死锁检测的时候，还是需要记录的。 LockManager 需要对外提供的四个方法实现如下：申请共享锁： 12345678910111213141516171819202122232425public void acquireSharedLock(TransactionId tid, PageId pid) throws TransactionAbortedException &#123; // 拿到页面对应的锁，如果还没有就新建一个 PageLock pageLock = getPageLock(pid); synchronized(pageLock)&#123; // 是排他锁且不是同一个事务（如果是同一个事务直接放行） while(pageLock.getLockState() == -1 &amp;&amp; !pageLock.holds.get(0).equals(tid))&#123; try &#123; pageLock.wait(10); // 阻塞 &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; &#125; if(pageLock.getLockState() &gt; 0 &amp;&amp; pageLock.holds.contains(tid))&#123; // 重入共享锁 - 不记录 return; &#125; // 锁空闲、是共享锁、有排他申请共享，这几种都放行 // 获取到锁后，记录已获取状态 pageLock.stateIncrement(1); // 共享数量+1 pageLock.holds.add(tid); addToLookups(tid, pid);\t&#125;&#125; 申请排他锁： 1234567891011121314151617181920212223242526272829public void acquireExclusiveLock(TransactionId tid, PageId pid) throws TransactionAbortedException &#123; PageLock pageLock = getPageLock(pid); synchronized(pageLock)&#123; // 只要锁不空闲，就不能获取排他锁（除非锁升级） while(pageLock.getLockState() != 0)&#123; // 该事务已经获取了共享锁，且它独占 if(pageLock.getLockState() == 1 &amp;&amp; pageLock.holds.get(0).equals(tid))&#123; // 升级为排他锁 - 放行且不记录 pageLock.stateIncrement(-2); // 此时lockState变-1 return; &#125;else if(pageLock.getLockState() == -1 &amp;&amp; pageLock.holds.get(0).equals(tid))&#123; // 该事务已经获取了排他锁，又重入 - 放行且不记录 return; &#125; try &#123; // 否则阻塞 pageLock.wait(10); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; &#125; // 获取到锁后，记录已获取状态 pageLock.stateIncrement(-1); pageLock.holds.add(tid); addToLookups(tid, pid); &#125;&#125; 这里直接在方法上加 synchronized 也是可行的，但是这样需要每次 notifyAll 所有阻塞的线程，针对性不强。因为每个页面有一个锁，不妨对 pageLock 加锁，这样每次只需 notify 一个阻塞在本页面的线程即可。注意后者需要在 wait 的时候设定等待超时时间，因为会出现别的线程先 notify 后，本线程才进入 wait 的情况，会永久阻塞下去，而设置超时时间后就会不停的循环判断锁条件。这是 wait/notify 方法的固有问题，如果想避免可以用 Semaphore 等其他工具。 释放锁： 12345678910111213141516171819public void releaseLock(TransactionId tid, PageId pid)&#123; PageLock pageLock = getPageLock(pid); synchronized(pageLock)&#123; pageLock.holds.remove(tid); // 从持有者中去除 removeFromLookups(tid, pid); // 从查询表中去除 if(pageLock.getLockState() == -1) &#123; // 如果当前为排他锁，更新为空闲 pageLock.stateIncrement(1); &#125;else if(pageLock.getLockState() &gt; 0)&#123; // 如果当前为共享锁，持有数-1 pageLock.stateIncrement(-1); &#125; // 当没有事务拿着锁了（空闲状态），或只有一个事务拿着锁（可能有锁升级不成功从而等待的情况） if(pageLock.getLockState()==0||pageLock.getLockState()==1)&#123; // 唤醒该页面阻塞的某个事务去竞争空闲锁或升级锁 pageLock.notify(); &#125; &#125;&#125; 死锁检测检测死锁通常是通过事务之间的等待关系图是否有回路（循环等待）来判断，具体的方法有两种： 拓扑排序：反复寻找一个入度为 0 的顶点，将顶点从图中删除并同时删除它的所有出边，如果最终图中全部剩下入度为 1 的顶点，则图中有回路；如果最终全部顶点都被删除，则不包含回路。 DFS：从所有的点开始进行深度优先搜索，如果一条 DFS 路线中有顶点被第二次访问到，则图中有回路，否则不包含回路。 本实验采用 DFS 方法。 设计死锁检测器类 DeadlockDetector： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class DeadlockDetector &#123; // 图的邻接表 private Map&lt;TransactionId, List&lt;TransactionId&gt;&gt; adjList; // 顶点状态 - null/0:未访问，1:已访问，2:在递归栈内 private Map&lt;TransactionId, Integer&gt; nodeState; public DeadlockDetector()&#123; adjList = new ConcurrentHashMap&lt;&gt;(); nodeState = new ConcurrentHashMap&lt;&gt;(); &#125; // 阻塞将要发生 - 进行记录 public void blockOccurs(TransactionId tid, List&lt;TransactionId&gt; listToWait)&#123; adjList.put(tid, listToWait); &#125; // 事务被唤醒 - 删除记录 public void notified(TransactionId tid)&#123; adjList.remove(tid); &#125; // DFS检测是否有回路 public boolean detectCycle()&#123; nodeState.clear(); for(TransactionId tid:adjList.keySet())&#123; if(dfs(tid))&#123; return true; &#125; &#125; return false; &#125; private boolean dfs(TransactionId tid)&#123; nodeState.put(tid, 2); // 标记入递归栈 List&lt;TransactionId&gt; adj = adjList.get(tid); if(adj != null)&#123; for(TransactionId t:adj)&#123; // 跳过自反边的情况 - 单个锁升级等待不算死锁 if(tid.equals(t)) continue; int state = nodeState.getOrDefault(t, 0); if(state == 2)&#123; return true; // 找到环 &#125;else if(state == 0 &amp;&amp; dfs(t))&#123; // 递归 return true; // 找到环 &#125; &#125; &#125; nodeState.put(tid, 1); // 出递归栈，标记已访问 return false; &#125; 为了简便，不再设计顶点类，而是让每一个 TransactionId 代表自己的顶点，采用图的邻接表表示法。nodeState 记录 DFS 中顶点的状态。 每当发生一个阻塞就调用 blockOccurs 方法，因为是页面级的锁定，所以一个事务陷入阻塞后一定等待的是持有页面锁的所有事务，也就是 PageLock 里面 holds 列表所存储的事务。所以我们只需每次将 holds 传入第二个参数，当做该事务顶点的所有出边（表示等待）即可。当事务获得锁（或者发现死锁）后，调用 notified 方法删除该顶点的所有出边。 更新获取共享锁的代码如下（循环部分）： 1234567891011121314151617...while(pageLock.getLockState() == -1 &amp;&amp; !pageLock.holds.get(0).equals(tid))&#123; deadlockDetector.blockOccurs(tid, pageLock.holds); // 添加等待边 if(deadlockDetector.detectCycle())&#123; // 检测到死锁 deadlockDetector.notified(tid); // 移除等待边 // 抛出异常，SimpleDB会abort该事务 throw new TransactionAbortedException(); &#125; try &#123; pageLock.wait(10); deadlockDetector.notified(tid); // 移除等待边 &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125;&#125;... 获取排他锁同理。 DEBUG 记录 PageCache 中的 page 数量可能会小于 LockManger 中的 page 数量，所以在根据 LockManager 中的 Page 来 flush 的时候需要进行 null 判断。 在 Transaction system test 的 10 个线程测试中，出现了时而成功时而永久阻塞的情况。经过调试， 发现是在 flushAllPages() 的循环里卡住； 发现 pageCache 返回的 Iterator 会不停的给出同一个 next 页面，死循环； 发现原因是自定义的双向链表尾结点 tail 丢失链接，导致无法停止遍历； 发现是没有注意线程安全的问题。在之前实现 LRUBasedPageCache 的时候没有使用 ConcurrentHashMap 类和 synchronized 关键字，导致并发问题，修改之后就没有问题了。 多线程情况下，所有的 Map 都最好用 ConcurrentHashMap，List 最好用 CopyOnWriteArrayList，它们除了是线程安全的，还支持遍历时修改，不会报并发修改异常。 在实现死锁检测的时候要注意：当一个事务已经获取共享锁，又要升级为排他锁，此时如果共享数不为 1，那么就要阻塞，但这个时候就会出现自己等待自己的情况（等待图中体现为自反边），但这不是死锁（因为其他的共享锁事务在 release 时会进行唤醒，当共享数为 1 时就不继续等待了），不应该被识别。所以在 DFS 的时候要跳过自反边。"},{"title":"MIT6.830 SimpleDB 实现笔记 Lab 3","path":"/2023/09/27/Lab 3/","content":"上一个 Lab 完成的是查询过程，Lab 3 的内容是查询优化（Query Optimization），主要完成两个部分，表统计信息 TableStats 和连接优化器 JoinOptimizer。 Cost 模型在一次查询中，最耗时的部分就是多表 Join，然而采用不同的 Join 顺序的效率差别很大，这就需要进行优化了。本 Lab 基于成本（Cost）模型进行查询优化，分别关注scancost 和 joincost。 在 Lab 3 给出的说明文字中，关于 joincost 在 Cost 总述和嵌套 Join 的 Cost 处的含义有一些出入（一个不包含 scan，一个包含 scan），为了避免引起歧义，统一采用如下的描述： scancost 是扫描一个数据表所需要的时间，大部分由磁盘 I/O 消耗。 joincost 是连接两个数据表所需要的总时间，不同的连接方式计算公式不一样，它包含 scancost,由 I/O 和 CPU 消耗。 scancost 的计算公式如下： 1scancost(t1) = num_pages(t1) * io_cost_per_page 当我们采用嵌套循环连接时， joincost 的计算公式如下： 12joincost(t1 join t2) = scancost(t1) + ntups(t1) * scancost(t2) //IO cost + ntups(t1) * ntups(t2) //CPU cost scancost 取决于硬件速度和表的大小，joincost 取决于 scancost 和表的连接基数（cardinality）（在上述公式是 ntups） ，基数取决于谓词的选择性（selectivity），因此想要计算 joincost 就必须对每个表的选择性进行估计。 过滤选择性（Filter Selectivity）谓词过滤选择性（范围0-1）指的是表中的元组通过过滤谓词的比例。选择性越大，表的基数越大，反之则越小。 在 SimpleDB 中，每个表会有一个 TableStats 对象，维护该表的统计信息，其中包含 scancost 估计和某个谓词对该表某一列的 selectivity 估计。连接优化器（JoinOptimizer）会调用 TableStats 的方法获取目标表的相关数据，根据公式计算连接 Cost，以确定一个最优的（代价最小的）连接顺序（查询计划）。 关键问题在于如何对 selectivity 进行估计。最常用的方法是使用直方图（Histogram）。 具体来说，就是对该表的每一列建立一个直方图，每个直方图将该列从最小值到最大值分成若干个区间，每一个区间记录了落在该区间的元组数量。这样，在面对一个谓词时，我们可以很快地计算出通过该谓词过滤的大致元组数量。示意图如下： image.png 对于一个常量 const，假设它落到直方图某个区间的桶（bucket）高度为 h_b，宽度为 w_b，表中元组总数量为 ntups，那么： 对于谓词 f=const，选择性估计公式为：(h_b/w_b) / ntups。 对于谓词 f&gt;const，如上图的情况所示，阴影部分就是通过谓词过滤的部分，它分为两部分：在桶 b 内的阴影部分、桶 b 右侧的所有桶。b 右侧的所有桶的选择性的计算公式都和 f=const 一样，最后进行累加即可；而对于桶 b 内阴影部分的选择性，计算公式为：(h_b/ntups) / ((b_right-const)/w_b)，这个公式假设在桶 b 内元组均匀分布。 对于谓词 f&lt;const，与上同理，对于桶 b 内阴影部分的选择性，计算公式为：(h_b/ntups) / ((const-b_left)/w_b)。 对于&gt;=谓词，只需要把&gt;和=的选择性相加即可，&lt;=同理。 IntHistogram 实现要实现直方图，比较直观的方式是将每一个桶看做一个对象，这样在获取桶高和桶的左右边界时很方便。整个直方图就是一个桶数组。 首先新建一个内部类：Bucket 1234567891011121314public class Bucket &#123; public double left; // 这里要用double，因为max-min可能很小 public double right; public int height; public Bucket()&#123; this.height = 0; &#125; // 填充该桶，高度+1 public void populate()&#123; this.height++; &#125; &#125;// Bucket 数组private final Bucket[] histData; 实现选择性估计方法： 123456789101112131415161718192021222324252627public double estimateSelectivity(Predicate.Op op, int v) &#123; double selectivity = -1.0; // 注意查询的值不一定在最大最小区间内 // 结构化、简化代码，减少出错 switch (op) &#123; case EQUALS: selectivity = calculateEquals(v); break; case GREATER_THAN: selectivity = 1 - calculateLessThan(v) - calculateEquals(v); break; case GREATER_THAN_OR_EQ: selectivity = 1 - calculateLessThan(v); break; case LESS_THAN: selectivity = calculateLessThan(v); break; case LESS_THAN_OR_EQ: selectivity = calculateLessThan(v) + calculateEquals(v); break; case NOT_EQUALS: // 1 - Selectivity(=) selectivity = 1 - calculateEquals(v); break; &#125; return selectivity; &#125; 这里，把关键的计算过程封装成了其他函数，其实可以发现只需要实现等于和小于的选择性估计即可，其他的谓词都可以通过这两种推算出来。 估算等于的选择性： 123456private double calculateEquals(int v)&#123; int i = findBucketIndex(v); if (i &lt; 0) return 0; // 这里必须要+1，杜绝零点几的桶宽出现 return (double) histData[i].height / (((int)bWidth+1) * ntups); &#125; 估算小于的选择性： 1234567891011121314151617private double calculateLessThan(int v)&#123; int index = findBucketIndex(v); double selectivity = 0; if(index == -1)&#123; // 在最左侧 return 0; &#125;else if(index == -2)&#123; // 在最右侧 return 1; &#125;else&#123; // 在区间内，先算桶内的部分 selectivity = (double) histData[index].height / ntups * (v - histData[index].left) / bWidth; &#125; // 在算桶外的部分 for(int i=0; i&lt;index; i++)&#123; selectivity += (double) histData[i].height / ntups; &#125; return selectivity; &#125; StringHistogram 采用了一种简便的实现方式，即“套壳”IntHistogram。所有的 String 数据被按照一定规则转化为 int 类型，然后使用整型直方图去管理和统计。 TableStats 实现有了直方图这个工具后，对表的信息统计就很方便了，每一个 Table 会附带一个 TableStats，在初始化的时候就对该表的每一列新建一个直方图存储起来，当然这个直方图并不能实时更新，因为它的范围已经固定了，但是在一段时间内，它能够反应该表数据的大致分布情况，从而为查询做出优化。TableStats 需要根据不同的策略进行重建。 在 TableStats 初始化时，需要扫描两遍 Table： 第一遍计算每一列的最大最小值 第二遍为每一列新建一个直方图 Join Ordering有了 TableStats 的各项统计信息，我们就可以对一个 Join 进行优化了，所谓的优化其实就是生成一个代价最小的 Join 执行计划。 对于一系列需要 Join 的逻辑表对（LogicalJoinNode），我们采用 Selinger 算法进行动态规划查找，找到代价最小的计划。 1234567891011121314151617181920212223242526272829303132333435public List&lt;LogicalJoinNode&gt; orderJoins( Map&lt;String, TableStats&gt; stats, Map&lt;String, Double&gt; filterSelectivities, boolean explain) throws ParsingException &#123; // 连接对 Set&lt;LogicalJoinNode&gt; joinSet = new HashSet&lt;&gt;(joins); // join order 缓存 PlanCache planCache = new PlanCache(); int size = joinSet.size(); for(int i=1; i&lt;=size; i++)&#123; // 遍历子集合 Set&lt;Set&lt;LogicalJoinNode&gt;&gt; sets = enumerateSubsets(joins, i); for(Set&lt;LogicalJoinNode&gt; set:sets)&#123; double bestCost = Double.MAX_VALUE; CostCard bestPlan = null; // 找到本次bestPlan for(LogicalJoinNode joinNode:set)&#123; CostCard costCard = computeCostAndCardOfSubplan(stats, filterSelectivities, joinNode, set, bestCost, planCache); if(costCard != null &amp;&amp; costCard.cost &lt; bestCost)&#123; bestCost = costCard.cost; bestPlan = costCard; // 这里面包含着计划 &#125; &#125; if(bestPlan != null)&#123; planCache.addPlan(set, bestPlan.cost, bestPlan.card, bestPlan.plan); &#125; &#125; &#125; if(explain)&#123; printJoins(planCache.getOrder(joinSet), planCache, stats, filterSelectivities); &#125; // 返回最优的join order return planCache.getOrder(joinSet); &#125; image.png"},{"title":"MIT6.830 SimpleDB 实现笔记 Lab 2","path":"/2023/09/08/Lab 2/","content":"Lab 2 和 Lab 3 都与数据库的查询过程有关，在执行查询的过程中会先后生成LogicalPlan和PhysicalPlan。逻辑计划由一系列的逻辑算子结点列表组成，它保存了需要进行 Scan、Join、Filter 等操作的表名、列名、谓词等信息。由逻辑计划生成的物理计划其实就是一系列物理算子嵌套形成的结点树。 火山模型SimpleDB 采用的是最经典且最广泛使用的查询模型：火山模型（Volcano），也叫流水线模型（Pipeline）。 该模型要求：每一个物理计划算子（Operator）都要实现 next() 方法，在该方法中，循环调用它的 child 算子的 next 方法以获取元组并进行数据处理，根据本算子的逻辑返回给父算子一个元组。直到 child 没有元组可获取，则返回 null。因此数据是从最底层数据表，一层一层的经过中间算子的处理、过滤，被传递到顶层的客户端的，因此被形象地叫做“火山模型”。而“流水线”的意思是，每当父算子调用 child 的 next 方法后，如果它想调用下一次 next，就只能等待这一次获取的数据经过物理计划自底向上的“流水线算子”的处理直至“涌出”，这期间父算子无法做其他事情。 火山模型的优点是每一层的算子只需要无脑从子算子获取元组，并根据自己的逻辑考虑如何返回元组给父算子，而不需要关心父算子和子算子具体的逻辑和实现。 在 SimpleDB 中，最顶层的算子是 Project（投影），它负责把所有的结果元组按照查询要求只显示指定的 Field 列；最底层的算子是 SeqScan（顺序扫），它负责从指定的数据表中一行一行的顺序读取元组；在这两者之间的算子有：Aggregate, Filter, Join, OrderBy, Insert, Delete 等。其中 Insert 和 Delete 比较特殊，因为他们不从数据表读取数据，而是从要插入或删除的元组集合中读取数据。 Lab2 总共有 5 个 exercise，主要练习了与执行计划相关的各种 execution 操作。比如过滤、连接、聚合、插入、删除等操作。每一个操作算子都继承了 Operator（OpIterator）类，它们会： 接受一个 child OpIterator，用以读取（遍历）目标数据； 接受一些控制该算子的参数； 同时实现 hasNext()、next() 等供外界遍历的方法。 Exercise 1 src/java/simpledb/execution/Predicate.java src/java/simpledb/execution/JoinPredicate.java src/java/simpledb/execution/Filter.java src/java/simpledb/execution/Join.java 谓词和连接谓词的作用是根据指定的 field 、操作符和操作数来判断某一个 Tuple 是否需要过滤。而 Filter 和 Join 算子则遍历 child 数据，利用上述谓词来进行来进行过滤，返回留下来的 Tuple。实现起来比较简单。 这里有个注意的点是，每个实现了 Operator 的算子都要重写 getTupleDesc() 方法，生成该算子每次 next() 后返回的元组结构描述。比如 Join 算子返回的是两个元组合并后的结构： 123public TupleDesc getTupleDesc() &#123;\treturn TupleDesc.merge(child1.getTupleDesc(), child2.getTupleDesc());&#125; Exercise 2 src/java/simpledb/execution/IntegerAggregator.java src/java/simpledb/execution/StringAggregator.java src/java/simpledb/execution/Aggregate.java IntegerAggregater 和 StringAggregator 是具体类型的聚合器，它们的作用是在聚合算子 Aggregate 遍历表的过程中统计分组（group）信息并得到最终聚合结果。Integer 类型有五种基本聚合操作：MIN, MAX, SUM, AVG, COUNT，而 String 类型只有 COUNT 一种。不同的聚合操作进行不同的计算即可。 Exercise 3, 4 src/java/simpledb/storage/HeapPage.java src/java/simpledb/storage/HeapFile.java src/simpledb/BufferPool.java insertTuple() deleteTuple() src/java/simpledb/execution/Insert.java src/java/simpledb/execution/Delete.java 练习 3 和练习 4 要求实现 HeapFile 和 HeapPage 的可变性，即可以随时插入、删除元组，并且实现 Insert 和 Delete 算子。 首先，向 HeapPage 中插入元组需要根据 header 标志位找到一个空闲 slot，在插入后（数组赋值）header 对应位置标志为 1；删除元组则反之。因为 header 使用 byte 数组存储的，所以需要一定算法将对应 byte 取出更改某一位值后再放回： 123456789101112131415private void markSlotUsed(int i, boolean value) &#123;\tbyte markBit = value?(byte)1:0;\tbyte oldByte = header[i/8];\tbyte newByte = (byte) 0 ;\tfor(int pos=7; pos&gt;=0; pos--)&#123; // 这里注意顺序 byte originBit = (byte) (oldByte &gt;&gt; pos &amp; 1); // 不变的bit if(pos == i%8)&#123; // 到了要设置的bit newByte |= markBit; &#125;else&#123; newByte |= originBit; &#125; newByte &lt;&lt;= pos!=0?1:0; // 除了最后一位，填充后左移\t&#125;\theader[i/8] = newByte;&#125; HeapFile 的插入方法需要遍历所有的 HeapPage，判断页面是否有空闲 slot，如果有的话，调用该页的 insert 方法，如果所有页面都无空闲，就要新建一个页面再行插入。 而最终所有的应用程序在插入元组时，是调用 BufferPool 的方法。BufferPool 调用 HeapFile 的 insert 方法，接收一个 Page 列表，存储所有被影响的页面（如果不考虑副本的话只有 1 个页面）。这些页面就是所谓的脏页（dirty page），即在缓存中发生了改动但还没有同步到硬盘中的页面。BufferPool 需要将这些页面标记为“脏页”。 BufferPool、HeapFile、HeapPage 之间必须遵循固定的调用关系： image.png Exercise 5 src/java/simpledb/storage/BufferPool.java evictPage() 练习 5 要求在缓冲区满了以后实现页面置换算法。因为之前没有考虑这个功能所以 getPage() 方法要重新写。 最常见的置换算法是 LRU（最近最久未使用算法），实现它可以用一个 List，每次访问一个页面就把它放到表头，这样需要同置换时，表尾的页面就是最近最久未使用的，直接逐出。然而仅仅用一个 List，在访问页面时还需要遍历查找，不如 HashMap 高效，但是仅仅用 HashMap 又无法实现算法要求。 所以我将两者结合，自定义了一个 PageCache 接口和 LRUBasedCache 实现类，手动实现双向链表，结合 HashMap，实现了 O(1) 复杂度 GET、PUT 操作和灵活置换的 LRU 算法。 页面缓存接口 PageCache： 123456789101112131415161718public interface PageCache &#123; // 向缓存中添加页面 void putPage(Page page); // 系统内部获取页面 - LRU不生效 Page getPage(PageId pid); // 外部（事务）获取页面 - LRU生效 Page accessPage(PageId pid); // 从缓存中删除页面 void removePage(PageId pid); // 缓存是否已满 boolean isFull(); // 下一个要被置换的页面PID PageId pidToBeEvicted(); // 置换页面（删除） void evictPage(); // 页面迭代器 Iterator&lt;Page&gt; iterator(); &#125; 实现类 LRUBasedCache 主要就是维护一个双向链表和一个 PageId 到链表节点的映射，然后在 accessPage 的时候实现 LRU 规则（将被访问的节点向链表头移动）： 12345678910111213141516171819202122232425262728293031323334353637383940public class LRUBasedCache implements PageCache&#123; /** * 双向链表结点 */ private static class Node&#123; Page page; Node pre; Node next; public Node(Page page)&#123; this.page = page; &#125; &#125; private final int capacity; private Map&lt;PageId, Node&gt; map; private Node head; private Node tail;\t...\t@Override public synchronized Page accessPage(PageId pid) &#123; Node node = map.get(pid); if(node == null)&#123; return null; &#125; moveToHead(node); // LRU算法 - 向链表头部移动 return node.page; &#125;\t@Override public synchronized PageId pidToBeEvicted() &#123; Node n = tail.pre; while(n != head)&#123; if(n.page.isDirty() != null)&#123; // 确保不是脏页（no-steal规则） n = n.pre; continue; &#125; break; &#125; return n==head?null:n.page.getId(); // 返回null代表全都是脏页 &#125;\t...&#125; image.png image.png"},{"title":"MIT6.830 SimpleDB 实现笔记 Lab 1","path":"/2023/08/09/Lab 1/","content":"6.830是麻省理工学院（简称 MIT）的一门计算机科学课程，全名为”6.830: Database Systems”。该课程是关于数据库系统的高级课程，旨在教授学生关于数据库的设计、实现和优化的知识和技能。 课程附带了6个Lab以供练习，最终目的是使学生能够用Java写出一个简易数据库系统，这6个Lab由浅入深，覆盖了数据库的核心知识点。 Lab1 总共有 6 个 exercise，主要是练习的是数据库的数据存储部分。 Exercise 1 src/java/simpledb/storage/TupleDesc.java src/java/simpledb/storage/Tuple.java 在 SimpleDB 中，逻辑上的存储单元由大到小分别是 Database -&gt; Table -&gt; Tuple -&gt; Field。一个表中的每一条记录就是一个 Tuple 元组对象，元组中的每一列是一个 Field 字段值，目前只实现了 Int 和 String（固定长度）类型。 每个元组需要一个 TupleDesc 对象来描述该元组包含的所有字段，包括每个字段类型 fieldType 和字段名 fieldName，在 SimpleDB 中由 TDItem 对象存储。 在实现 TupleDesc 的 toString() 方法时，发现了一个显而易见但之前没注意到的问题：集合每次在调用 iterator() 方法时都会生成一个新的 Iterator，所以不能反复调用此方法。另外 for-each 语句不能用于 Iterator，只能用于数组或实现了 Iterable 接口的对象。 Exercise 2 src/java/simpledb/common/Catalog.java Catalog 是管理数据库所有表的单例对象，比较简单。 主要实现了供外界调用的 addTable、getTableName 等方法 在 SimpleDB 中，一个 Table 对应一个 DbFile，并且共享同一个 ID（DbFile 绝对路径的 hashcode） 这里的 HashMap 用并发安全的比较好 Exercise 3 src/java/simpledb/storage/BufferPool.java 实现 getPage() 方法 BufferPool 也是一个全局单例对象，它负责维护访问页面 Page 的缓存。关于页面，有三个容易混淆的概念： 硬盘中的页面（也可以叫块 block） 操作系统中的页面 数据库中的页面Page 是数据库向硬盘中读取和写入一次数据的最小单位，一般来说数据库的页面比底层的页面要大一些，所以需要我们自己写一些逻辑来保证操作的原子性（暂时不需要）。 每次通过 PageId（存储 tableId 和 pageNo）来获取页面。首先查找缓存，没有的话就通过 Catalog 获取 DbFile 读取页面并加入缓存。如果缓存占满，就要进行页面置换（暂时不需要）。 1234567891011public Page getPage(TransactionId tid, PageId pid, Permissions perm)\tthrows TransactionAbortedException, DbException &#123;\tPage res = idToPage.get(pid);\tif(res == null) &#123; Catalog catalog = Database.getCatalog(); DbFile f = catalog.getDatabaseFile(pid.getTableId()); res = f.readPage(pid); idToPage.put(pid, res);\t&#125;\treturn res;&#125; Exercise 4 src/java/simpledb/storage/HeapPageId.java （继承自 PageId） src/java/simpledb/storage/RecordId.java src/java/simpledb/storage/HeapPage.java （继承自 Page） 前两个 Id 对象主要就是 hashcode() 和 equals() 方法的编写，注意： 在重写一个类的 equals 方法的时候，必须同时重写 hashCode 方法。否则的话，在使用需要判断 hash 值的数据结构（如 HashMap）进行存储时就会出现问题。要求： equals 为 true 时 hashCode 一定为 true；hashCode 为 true 时，equals 不一定为 true。 HeapPage 是实际存储在缓存中的页面（从硬盘读取到内存），它主要包含头部 header 标志位和一个固定长度的 tuple 数组（slots），结构示意图如下： 页面中的 slot（插槽）有几个，header 就有几位，当一个元组插入 slot 后，header 对应位置设置为 1，删除元组则反之。在 SimpleDB 中，一个 table 的 TupleDesc 确定下来后，tuple 的长度就是固定的，因此可以计算出该页面可以有多少个 slot，用于初始化 header 和数组。 计算 slot 个数： 123456private int getNumTuples() &#123; // 每个页面可存储的元组数计算公式（大小单位是字节）：\t// 页面大小 * 8 / (元组大小 * 8 + 1)，向下取整\tint numTuples = BufferPool.getPageSize()*8 / (td.getSize()*8+1);\treturn numTuples;&#125; +1 是因为每个元组要附带一个标志位。 计算 header 大小（字节），多余的 0 位不考虑： 12345private int getHeaderSize() &#123; // Header要存储numSlots个bit，计算所需的bytes\tint headerSize = (int) Math.ceil(numSlots / 8.0); // 向上取整\treturn headerSize;&#125; HeapPage 在初始化时接受一个 pageId 和从硬盘读入的序列化后的 byte 数组进行反序列化，相反，getPageData 方法将该页面序列化以存入硬盘。 需要实现 isSlotUsed() 方法，该方法返回某个 slot 是否插入了元组。检查 header 对应位置的标志位是否为 1 即可。 12345public boolean isSlotUsed(int i) &#123;\t// 注意规定了从每个byte从右到左（low to high）\tbyte slot = (byte) ((header[i/8] &gt;&gt; (i%8)) &amp; 1); return slot == (byte)1 ? true : false;&#125; Exercise 5 src/java/simpledb/storage/HeapFile.java （继承自 DbFile） HeapFile 对应一个表在硬盘中存储的文件，存储的单位是 HeapPage，所以主要是实现 readPage() 方法，它接受 pageId，需要找到对应 Page 在文件中的偏移量读取出来。一定要用文件随机读取，而不能一次性全部读到内存中，因为文件可能会很大。 12345678910111213141516public Page readPage(PageId pid) &#123;\t// 找到对应Page所在的偏移量，读取后生成HeapPage\tint pageSize = BufferPool.getPageSize();\tint offset = pid.getPageNumber() * pageSize;\tbyte[] data = new byte[pageSize];\tPage heapPage = null;\ttry (RandomAccessFile f = new RandomAccessFile(file, &quot;r&quot;)) &#123; f.seek(offset); f.read(data); heapPage = new HeapPage((HeapPageId)pid, data);\t&#125; catch (IOException e) &#123; e.printStackTrace();\t&#125; return heapPage;&#125; 另外的一个难点是实现 iterator() 方法，它的功能是遍历该表（DbFile）中的所有元组。那么就需要我们遍历 HeapFile 的所有 HeapPage，过程中使用 HeapPage 的 Iterator 来遍历元组。但是上面实现的 readPage() 方法是给 BufferPool 调用的，因为所有的页面读取都要经过缓存。所以我们需要调用 BufferPool 的 getPage() 方法来获取页面，从 pageNo = 0 开始累加，直到到达该文件所存储的页面数量的上限，是在 numPages() 里计算得到的（文件大小除以 PageSize）。 Exercise 6 src/java/simpledb/execution/SeqScan.java （实现 OpIterator） Operator 是执行计划的基本单位，最简单、最底层的一个 Operator 就是 SeqScan，按照存储顺序扫描某一个表的全部元组。 这里主要添加了表的别名 alias的概念，我们需要生成一个 tableAlias.filedName 形式的 TupleDesc 以供后续使用。 实现 OpIterator 接口的全部方法，主要是调用 HeapFile 里的 Iterator 的相应方法。 详细的数据库查询模型在下一个 Lab 总结。 image.png"},{"title":"RDD分区与并行计算","path":"/2023/03/28/RDD分区与并行计算/","content":"分区应该是 Spark 中最基础、最核心的概念了，首先搞要清楚为什么要分区。不分区，分布式并行计算就无从谈起。其实哪怕不是分布式，就是如今在一台电脑上 8 个核心也都是标配了，如果把所有的计算任务全都交给一个核心处理便是对硬件资源的极度浪费，效率也十分低下。而要想不浪费，就要采用 并行计算 ，让每一个核心处理一部分任务。而不同的计算需要独立的上下文环境，这就引入了 分区 的概念。每个分区拥有自己的数据和计算函数，当所有的分区计算完毕后，再将它们的结果合并输出。Spark RDD 在逻辑上实现了以上的分区概念。 第一，在 Spark 中几乎所有功能的数据操作都是以 RDD 为单位的（当然还有累加器和广播变量，但是它们都有固定的应用场景），所以它可以看做在 Spark 中的一个“万能数据集”，不论什么数据都能往里面放，不论在哪个场景都可以用，首先明确这一点（其实是为了打破初学者对它的陌生感）。 第二，所谓分区（Partition），简单来讲就是 RDD 在内部将数据分成的不同 切片 ，从不同的数据源读取数据会按照不同的方式进行切片，因此不同的数据源往往会对应不同类型的 RDD 实现类，而每个 RDD 实现都有一个独立的 Partition 实现类来处理数据。在 Partition 实现类中，会用不同的方法存储实实在在的数据。不过这里要搞清楚，RDD 是惰性计算的，只有在执行行动算子后，数据才会在各种不同的 RDD 分区中 计算、接收、传递 ，并不做停留。因此我的理解是，每个 RDD 分区调用它所 依赖的上一级 RDD 的对应的分区计算方法，获得新的分区数据，这本质是一个 链式调用 。这样行动算子会触发数据从读取到一步步计算的链式调用，最终获得计算结果，可以看做分区是固定的，数据一直在变化。 由上所知，在没有发生 Shuffle 的时候，分区数量不变，不同分区之间的计算是 平行的 ，互不干扰，谁快一点谁慢一点都无所谓，重点是它们在同时计算，这就是并行计算。而在遇到了像 groupByKey、orderBy 这样的需要打乱原有数据的方法，分区之间不可能再相安无事了，它们需要相互交换数据，即进行 Shuffle。Shuffle 操作需要数据 落盘 因此十分低效。而当发生 数据倾斜 时，Shuffle 又能够有效地保证计算的 负载均衡 。 第三，RDD 在逻辑上实现了分区，而在集群上实际的计算如何实现的呢？这就要提到 RDD 的任务执行单位：Job、Stage、Task。简单来说，Job 对应一个行动算子，它内部通过 RDD 谱系图 划分 Stage，通常是遇到一个 Shuffle 操作会生成一个新的 Stage。每个 Stage 根据 RDD 的分区数目生成 Task，一个 Task 对应一个分区。注意 Task 运行的结果是目标 RDD 的一个分区，而不是相反。前两个仍然是逻辑上的，真正可以运行的是 Task。Task 是在 Executor 上运行的，每一个物理节点可以起一个或多个 Executor。 所以最终的运行模型是：Driver 端（就是写 Spark 程序的地方）生成 SparkContext 作为和 Spark 框架连接的入口，它会进行 DAG 图构建、Stage 划分、Task 生成等一系列操作，这些操作是在一个节点完成的。而封装好的 Task 会发送给 Yarn 等调度器进行调度，可能会根据 “计算向数据移动” 等准则分发给不同的节点的 Executor，从而进行计算。 知识点： RDD 计算时（行动算子）在 一个分区 内是一个一个数据根据谱系图执行逻辑，即前面一个数据的逻辑全部执行完毕后才轮到下一个数据。分区内部的数据执行是 有序的 ，不同分区之间的数据执行是 无序的 。 MapPartitions 可以以分区为单位进行数据转换操作，但是会将整个分区的数据加载到内存中进行引用，容易出现内存溢出。 窄依赖： 如果新生成的 child RDD 中每个分区都依赖 parent RDD 中的一部分分区，那么这个分区依赖关系被称为 NarrowDependency。 宽依赖： 表示新生成的 child RDD 中的分区依赖 parent RDD 中的每个分区的一部分。"},{"title":"数据可视化","path":"/2023/03/10/数据可视化/","content":"生活中数据可视化无处不在，以前都会有意无意地进行过可视化的工作，但是通过专业化的分析和方法设计出的结果会更能达到可视化的目的，设计过程也会更加得心应手。另外数据可视化有时候并不只是数据的展现，还包含着数据的挖掘。比如看到一批数据，从不同的角度和考量进行可视化可能会从中挖掘出不同的信息。 本文是北京大学袁晓如老师《数据可视化》课程的学习笔记链接：数据可视化 - 华文慕课 - 中文MOOC平台 (chinesemooc.org) 第 1 章概念 数据可视化就是把一些复杂的数据转化成人们能够直接看到并理解的图形或图像，有利于我们更快地识别特征，发现知识。基于计算机的可视化系统通过对数据的视觉表达形式来帮助人们更有效地完成特定任务。 不同的领域、不同的任务、不同的受众的可视化构型是不同的，要做合理、有效的选择。 要考虑计算限制、人类限制、显示限制 总结第一章讲述了可视化的概念、构型和案例，其中构型的选择非常重要，需要考虑不同的领域、任务、受众和限制因素，要在多对矛盾中进行权衡。 第 2 章数据类型 数据集类型 结构化数据：已知数据类型、语义 表格（Tables） 网络（Networks） 场（Fields） 空间/几何（Spatial/Geometry） 多维表（Multidimensional Table） 树形（Trees） 非结构化数据：没有预定的数据模型，如文字、视频、图像。需要转化为结构化数据（NPL、文本挖掘） 数据类型：数据项、链接、属性、位置、网格 属性类型：定类型、定序型、定量型。不同的属性需要用不同的通道表示。看到一个可视化就分析有什么属性，看到属性就要想是什么类型。 表达力和有效性：服从一致性和重要性排序原则，一致性是指，视觉变量和数据属性应该匹配。 2.7 的设计案例有启发意义。 总结这一章主要介绍了各类数据集合数据的类型，目的是强调在可视化过程中，对属性类型的分析是十分重要的，不同类型的属性需要考虑不同的可视化方法，这决定着最后的呈现效果（千差万别）。要培养分析数据属性的思维。 第 3 章数据编码（具体步骤） 符号和通道 符号标记（Marks）：如用圆点和直线代表数据项和连接 点、线、面，（包含、连接、嵌套） 视觉通道（Channels）：符号标记的表现形式，如圆点的颜色 分为以下两个类型，顺序代表有效性从高到低 &lt;定类型&gt; ：空间区域、颜色、运动模式、形状 &lt;定序定量型&gt; ：位置、长度、倾斜度、面积、深度、亮度/饱和度、弧度、体积 考虑视觉通道的五个属性：选择性、关联性、量化性、可序性、容量 史蒂文心理物理强度定律：强度由高到低：饱和度、长度、面积、深度、亮度，感官测试：The eyeballing game (woodgears.ca) 不同类别应该采取的通道排序：image.png 总结直观地感受了各类视觉通道的差异和优缺点，在可视化的时候首先要选择正确的符号和通道，让人们有对数据更加准确的感受。 第 4 章可视化任务与分析 分析三要素： 对象：判断第二章所述的数据类型和属性类型 手段：将第三章所述进行实践 目的：考虑用户需求（什么样的用户） 可视化任务抽象。不同的可视化有不同的任务，这里的任务（功能）是从用户的角度出发，用户为什么需要可视化，该可视化想要用户得到什么信息。要识别任务-数据组合，寻找可能的解决方案。即分析三要素中的目的（行动和对象），行动有以下三个层次（由高到低）：分析、搜索、查询。image.png image.png 分析三要素中的对象，对于不同的对象关心不同的特点： image.png 分析三要素中的手段，考虑可视化构型：视觉编码、交互。（后面讲） 可视化设计验证四层模型：image.png 所谓问题导向就是某个领域的某个问题需要可视化，这时四层模型从外到内进行工作。所谓技术导向就是某个新型的可视化技术出现了，从内到外去寻找可以可视化那些领域问题。 详细学习 4.5 可视化案例。 总结讲述了可视化过程中需要完成哪些分析工作，有哪些要素。从一个顶层抽象的角度阐述了可视化的整个流程。 第 5 章交互 视图操纵的方法 视图随时间变化 重新编码，对于对象 调整参数，不同的小控件（滑块、按钮等） 调整布局、顺序，What、How、Why 重排，对复杂的表格不同的维度（Table Lens）/ 平行坐标 调整对齐方式，堆叠柱形图 过渡动画，在两个状态间做插值平滑 视图分面（Facet） 并置视图（重要）：把两个图放在一起关联 image.png，动态查询是一个经典的例子，快速、增量式和可逆的交互操作。 分隔视图 image.png 叠加视图 image.png 数据约简（Reduce） 过滤：交叉过滤（一个维度变化，另外跟着变） 聚合：空间聚合 不完全互斥可视化系统：Jigsaw总结讲述了可视化中最有趣但却做复杂的交互操作，介绍了视图操纵的几种方法，通过例子体会到不同交互方法的特点和功能，恰当的交互能够给用户带来良好的体验的同时，也能够让用户有更多的发现。 第 6 章光与颜色 颜色表现不止于单一的颜色，还要考虑背景色，和周围的颜色（上下文）。 环境颜色会增加其自身的相反颜色以获得更强的对比 深色增加浅色 红色增加绿色 蓝色增加黄色 感知差异依赖于背景 颜色模型：《CIE 标准观测》 色度图 RGB 色度（三角形） 投影色域 对立色彩 颜色设计准则（经验） 需要考虑上下文，这里的上下文是指除颜色设计之外的各种对象与概念。（比如用户和预算等） 并不是五彩缤纷就是好的，好的设计让信息更吸引人。 颜色包括 &lt;色相、饱和度、亮度&gt; 三个属性，要精确区分。 控制明度，确保易读性 控制色相种类，定义颜色分组，避免太多颜色竞争而混乱，控制“弹出效应” 使用中和背景，最小化 “同时对比效应” 在不同的可视化场景，根据颜色标注的目标不同，颜色的选择也不同。比如飞机上的仪表盘属于需要快速反应的场景，颜色不能太多。 ColorBrewer: Color Advice for Maps (colorbrewer2.org) 网站提供不同的配色方案。 总结在使用颜色的时候需要考虑很多因素，比如对比、色盲等。在设计的时候需要遵循设计准则，让颜色起到增进理解而不是相反的作用。首先要理解颜色的各种属性，精确区分，谨慎选择。 第 7, 8 章表格表格分为平面表格（唯一索引）和多维表格（基于多个键的索引）。 平面数据 表格数据的比较 条形图（可以有不同方向）：要注意基准问题（起始值是否从 0 出发）；要注意是用线性变换还是对数变换，这里的变换是指纵轴单位长度的变化。 折线图：可用【光滑】【连接】和【散点】。要注意如果两个数据点之间连接起来，代表这个属性是可以插值的（比如年龄），如果属性不能插值（比如性别分类）则不能随意连接起来。 散点图：常常用于揭示两个维度之间的相关性。如果有第三维的话，可以将其映射到其他的视觉属性，比如颜色、大小；要注意不要过度绘制，要善用透明度和趋势线。 饼图/圈图：用于表示数据的组成。强调精确数值时用条形图，强调比例时用饼图。 堆叠条形图：将圈图拉直放到坐标系中，比饼图更加直观。 堆叠面积图：将离散的堆叠条形图连接起来。 表示数据的分布的图： 【直方图】与柱状图的区别是没有间隙，横轴是某个属性的区间划分；经验法则：根据数据量的平方根来确定划分区间的数目。 【密度图】 【箱型图】 【小提琴图】 【热力图】 表格可视化经典方法：Table Lens（表格透镜） 高维数据 散点图：点的位置表示两个属性，点的大小、颜色表示更多的属性，但往往表示不了高维（大于三个维度）。 散点矩阵图：每行/列是一个维度，每个单元格绘制两个维度的散点图。下图是 4 个维度两两之间的关系：image.png SPLOM 聚合-热力图：类似于散点图，减少计算量。image.png 相关热力图 Rolling the Dice：两个散点图无缝转换 平行坐标：将 x,y,z 等坐标轴平行放置，可以引入更多的维度，一条连线代表一个数据项，适用于异构数据。当数据量较大的时候，采用 &lt;增加透明度、捆绑、采样&gt; 来解决杂乱问题。 image.png 降维：保留尽可能多的变化，绘制低维空间，主成分分析。 多维缩放：让两两之间在平面的距离尽量正比于在高维空间的距离。常用于文本分析。 地形图表示。 维度嵌套/堆叠： 维度有限，工程数据分析常用 多方法耦合：平行坐标+散点图 其他方法：太多了，看 8.6 节 总结详细讲述了各种图对于表格数据可视化的作用，适当进行选取。 第 9, 10 章网络结构 层次结构（树）：用于有组织结构、分级分类的数据，有谱系树、进化树、搜索树、决策树。 显式树可视化 Reingold-Tilford 布局：类似思维导图 DOI 树（突出焦点）：树节点过多，只强调部分节点（增大），或用三角形代表不重要的子树。 双曲线树（突出焦点）：面向大规模的层次结构数据，全体数据可见，焦点放大。image.png 隐式树可视化：看不见树的结构，但是树的内部关系。较重要的是包含式非显式布局。其中最重要的是【树图】（Treemap）：切分空间，节点为长方形，节点面积代表相应属性。 树比较可视化：用柱状图进行树之间的比较。 图的可视化 两种主要类型的任务：【基于属性】、【基于拓扑】。 显式图形式：image.png，布局标准如下，减少用户阅读的干扰（不用全部满足）： 最小化边交叉 最小化相邻接点的距离 最小化绘图区域 边长度统一 最小化边弯曲 最大化不同边之间的角距离（过多的锐角不容易分辨） 宽高比约为 1（不太长也不太宽） 对称性（类似的图结构看起来相似） 矩阵形式：即图的邻接矩阵。非常适合邻域相关的任务，不适合路径相关的任务；节点的顺序很重要，排序后可能会发现规律。 混合显示与矩阵形式：NodeTrix。image.png 力导向布局算法：边=弹簧，点=互斥磁铁，算法开销较大 image.png 总结不同可视化方法之间需要进行取舍，为了相应的目的，可能会降低对另外一部分性能的支持。不同的可视化方法可以混用，可能达到更好的效果。 第 10 章时间序列时间序列数据就是其中一个变量是时间的数据，也可以说是高维中一个维度是时间的数据。vcg.informatik.uni-rostock.de可视化方法有： 缩略组图（Small Multiples）：在单个页面上显示的呈缩略图大小的图形集，表示单个现象的不同方面（不同时间）。也适用于多变量（多维）显示。比如新冠晴雨表。 形态替换：将时间视为隐藏的维度，为每个时间帧生成一个可视化，然后播放动画，用户可以进行追踪（可以加上轨迹）。Gapminder Tools 。但是该方法有一个问题是变化盲视，即人们没有注意到场景中可见元素的变化，需要根据具体情况解决（如增加视觉编码）。 时间序列图：将横坐标规定为时间，纵坐标为属性（可以有多个，不同编码也可以嵌套堆叠）。对于多个时间序列的比较，有以下几种方法： 简单线图：多条不同的线在一起。 编织线图：交替地根据数值的大小进行前后排列。 计算曲线焦点并垂直切割曲线面积，按照深度排序优先绘制最高部分面积。 换句话就是：高个子永远在后面。 image.png 缩略视图：见前文。 水平线图：解决缩略视图在高度较小的情况下空间利用问题。（压缩高度，保留精度） 堆叠线图：把不同的线型堆叠在一起。 螺旋图：更好的体现周期性；注意比例和标注。 像素驱动方法：每个像素代表一个时间点。 一行行/一列列排布 用填充曲线（Peano-Hilbert）：时间上相近的，空间上也相近。 时间曲线（Time Curves）：时间顺序的排列并不是规则的（水平的），而是根据内容相似性进行分布（弯曲）。曲线的形状可以表示相应的演变。（高维映射到低维 / 多维缩放） 主题河流（ThemeRivers）：表示文本随时间的变化。 从左到右流经时间，类似堆叠曲线图 image.png 总结时间在可视化里面可以看做高维中的一个带有先后顺序的属性，所以时间序列可视化都是在视觉上具有一定的连续性，这种联系可以让人们更直观地感受时间的流动与事物的变化。 第 12 章地图 使用地图的原则和任务 原则：当空间关系被着重强调时使用地图 任务：寻找地点/特征、寻找从 A 到 B 的路径、辨认与地点相关的属性、基于地点比较属性 地图投影 - 将地球展开 要考虑的属性：面积、形状、方向、方位、距离、尺度 投影方法 墨卡托投影：投影至一个包裹着地球的圆柱上，再展开成平面。所有的经纬线都是直线前垂直相交；方位准确，面积不准确。 方位角等距投影：确定航线走向。image.png 温格尔投影：最小化三种失真（面积、方向、距离）。image.png 锥形投影 阿尔博斯等面积投影：正确显示面积 复合投影 其他投影方式：Extended geographic projections for d3-geo. (github.com) 区域分布地图 用区域填充的颜色或图案来表示数值，如美国大选地图 问题：具有误导性，因为某区域面积的大小可能与数值没有关系 解决方法：同一个颜色用深浅区分数值大小，或加入其他编码（如密度） 等高线地图：用来表述在空间中的数值分布，特别是数值之间的过渡。 统计/变形地图：舍弃了地理区域的真实面积，而用数值大小来决定面积（缩放），但保留了原地理区域之间的方位、接壤等信息。 比例标识地图：保留原地理区域的真实面积，而采用添加圆圈（或其他图形），用它的的大小或其他定量属性来代表数值的大小。 流图：用于表示数据在不同地域之间的流动。（交通部门） 地铁地图：采用伦敦地铁图方式。线路水平、垂直或 45 度，车站间等距。 总结地图可视化都是以真实的地理区域为基础，而自然地理区域的面积、方位是固定的，想要表示的数据又往往与面积、方位无关，这就需要考虑如何规避掉区域自然属性对可视化目的的干扰。 第 13 章经验法则大多数情况下简单的、经验性的、探索性的但不是很准确的原则，体系不完整。 慎用 3D（但是技术在发展） 屏幕不是三维的，更适合 2D 信息 人对深度的判断不够精确 会产生遮挡，无法了解相关关系，带来时间成本 透视会引起失真 3D 下的文本会倾斜，造成认知负荷 慎用 2D：能用 1D 的列表就不要用 2D，1D 更适合查找、排序任务。在可视化里面，能简则简，不要追求复杂（越简洁越有效）。 慎用多视图的简单组合：缺乏数据内在逻辑的关联，无法提供深度探索。多视图需要有侧重点，图与图之间要紧密联系，有紧密的交互。（有机结合） 可见性重于记忆：如果能够通过不同视图直接对比，就不要采用动画，因为动画要求用户记忆，带来负担。 分辨率优先：沉浸感依赖于分辨率。简单说就是优先提高分辨率，而不是整花里胡哨的东西。 概览优先，缩放与过滤，细节按需呈现：【大量数据 -&gt; 展示概览，忽略细节 -&gt; 提供提示 -&gt; 用户定位到感兴趣的地方 -&gt; 放大 -&gt; 涌现细节】 交互响应不可缺少：即时反馈非常重要，如不能即时，应告知用户处理进度或先显示一部分。 黑白情况下的可用性：可视化在黑白情况下依然有效。借用亮度、色度、饱和度等通道。 功能重于形式：坚持有效性优先原则，考虑用户需求。 总结经验法则是贯穿于所有可视化技术的原则，在进行可视化工作之前和完成之后，都可以对照经验法则检验工作是否得当。"}]