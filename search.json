[{"title":"MIT6.830 SimpleDB 实现笔记 Lab 4","path":"/2023/11/13/Lab 4/","content":"Lab4 是实现 SimpleDB 的并发事务系统，跟前面的内容相比较为复杂。 一般来说数据库的事务需要满足 ACID 特性，即原子性、一致性、隔离性、持久性。原子性就是该事务的所有操作要么全部完成，要么全部取消，要求通过下面的操作保证： 不从页面缓存中逐出“脏页”（被某个事务更新的页面）。——NO STEAL 规则 在事务正确提交时，强制刷新所有脏页到磁盘。 隔离性就是同时执行的多个事务不会相互干扰，通过将要实现的锁机制保证。一致性在 SimpleDB 中没有强调，持久性应该在 Lab6 的恢复功能上体现。 SimpleDB 事务并发控制实现锁机制在数据库中锁定对象可以是表、页面、元组、属性等，SimpleDB 规定的锁定粒度是页面（Page）。可供事务获取的锁类型有两种：共享锁和排他锁，规则如下。 事务在读取页面之前，必须具有共享锁； 事务在修改页面之前，必须具有排他锁； 多个事务可以在一个页面上具有共享锁； 只有一个事务可以在一个对象有排他锁。在该规则下，如果一个事务在请求页面的时候，无法获取该页面的锁，就必须被阻塞，以等待锁资源被其他事务释放留给自己去竞争。特别的是，如果一个事物在申请排他锁时，如果已经持有了该页面的共享锁且是唯一一个持有者，那么可将此共享锁升级为排他锁（锁升级）。 两阶段锁（2PL）考虑两个事务按照上述锁机制正常执行，有可能发生下图的情况：（X 排他，S 共享） T1 和 T2 都正常提交了，但是 T1 对于页面 A 发生了“不可重复读”现象，即在同一个事务先后两次读到的数据有可能不一样（被别的事务如 T2 修改了）。 解决这个问题的办法就是实现两阶段锁协议（2PL）。2PL 的两个阶段分别是扩展阶段（Growing） 和 收缩阶段（Shrinking），在扩展阶段事务只能获取锁，在收缩阶段事务只能释放锁。 两阶段锁协议本身足以保证冲突可串行性，但它可能会导致级联中止（Cascading aborts） 问题，即一个事务的中止可能导致其他多个事务也一起中止。这是因为在 2PL 中一个事务可能基于另一个事务尚未提交的数据进行操作，如果那个事务被中止，就会发生级联中止。如下图： 为了避免这种情况，需要实现严格两阶段锁协议（Strict 2PL），即一个事务只能在它提交或中止时释放所有锁。SimpleDB 要求实现 Strict 2PL 协议。这其实简化了操作，因为在赋予事务锁的时候不用考虑什么时候执行完了操作该释放，而是通通等到最后 commit 时释放。 页面级锁机制实现刚开始时看到需要实现读写锁，自然会想到 JUC 中的 ReentrantReadWriteLock 类，然而该类是负责线程同步的，一个事务可以有多个线程，所以他们不在同一粒度。另外只用 Java 提供的这些类并不能很好地实现 2PL 协议，也并不契合事务并发场景。因此我们需要自己实现事务的读写锁机制，但是类库中的一些思想可以借鉴。 我们定义一个 LockManger 来负责维护事务和锁的状态，在 BufferPool 中事务只需调用相应的方法来获取和释放锁就行了。可以想到 LockManger 需要提供以下方法： 12345678// 获取共享锁void acquireSharedLock(TransactionId tid, PageId pid);// 获取排他锁void acquireExclusiveLock(TransactionId tid, PageId pid);// 释放锁void releaseLock(TransactionId tid, PageId pid);// 是否持有锁boolean holdsLock(TransactionId tid, PageId pid) 更新后的 BufferPool.getPage 方法如下（因为是页面级锁定，所以只在这里获取锁）： 123456789101112131415&#123; if(perm == Permissions.READ_ONLY)&#123; // 获取共享锁 if(!holdsLock(tid, pid)) &#123; lockManager.acquireSharedLock(tid, pid); &#125; &#125;else&#123; // 获取排他锁 - 存在锁升级情况，所以不判断holdsLock lockManager.acquireExclusiveLock(tid, pid); &#125; ... //缓存中获取页面 ... return page;&#125; 所谓事务获取到锁就是“放行”，获取不到就是“阻塞”。 这里的“锁”其实说成“锁的使用权”或“钥匙”更贴切一点。每个页面其实只有一把锁，需要钥匙才能进入访问。而共享锁，就是说这把锁可以有多把钥匙开启，每一把钥匙给一个事务；排他锁就是只能有一把钥匙给唯一的事务。如果事务获取不到钥匙就被阻塞。其实 Java 中的重量级锁也是这个道理，有时候会被“锁”这个名词给绕晕。 LockManger 的作用就是记录谁拥有某个页面的钥匙，是把什么样的钥匙，为了统一起见，下文仍称“锁”。 接下来是 LockManger 的实现，既然每个页面只有一把锁，并且需要维护这把锁的状态和与事务的关系，那么就可以设计一个 PageLock 类来管理： 12345678910111213141516class PageLock&#123; private PageId pageId; // 页面ID private int lockState; // 0:空闲,-1:排他锁,&gt;0:获取到共享锁的事务数量 CopyOnWriteArrayList&lt;TransactionId&gt; holds; // 获取锁到的事务 public PageLock(PageId pageId)&#123; this.pageId = pageId; holds = new CopyOnWriteArrayList&lt;&gt;(); &#125; // 避免并发修改 public synchronized void stateIncrement(int n)&#123; lockState += n; &#125; public synchronized int getLockState()&#123; return lockState; &#125;&#125; 用一个 lockState 记录这个页面锁的状态。等于 0 代表该页面是空闲的，没有事务访问（无人持锁）；等于 -1 代表该页面的锁为排他锁；大于 0 代表该页面的锁为共享锁，具体数字表示有多少事务正在共享该锁。holds 记录了都是哪些（个）事务获取到该锁。 在 LockManger 中，我们用一个 Map 记录页面和锁的对应关系；为了方便查询，同样用一个 Map 记录事务和其所持有的锁集合的对应关系： 12private Map&lt;PageId, PageLock&gt; pageLocks;private Map&lt;TransactionId, List&lt;PageId&gt;&gt; lookups; 在实现“阻塞”效果时，采用了 wait/notify 的方式，也可采用 JUC 中的各种合适的工具类。注意如果仅仅是为了实现读写锁的话，不需要我们自己记录哪些事务陷入了等待，因为这些工具内部已经实现了记录阻塞线程的逻辑，可以在需要时唤醒。但是在后面实现死锁检测的时候，还是需要记录的。 LockManager 需要对外提供的四个方法实现如下：申请共享锁： 12345678910111213141516171819202122232425public void acquireSharedLock(TransactionId tid, PageId pid) throws TransactionAbortedException &#123; // 拿到页面对应的锁，如果还没有就新建一个 PageLock pageLock = getPageLock(pid); synchronized(pageLock)&#123; // 是排他锁且不是同一个事务（如果是同一个事务直接放行） while(pageLock.getLockState() == -1 &amp;&amp; !pageLock.holds.get(0).equals(tid))&#123; try &#123; pageLock.wait(10); // 阻塞 &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; &#125; if(pageLock.getLockState() &gt; 0 &amp;&amp; pageLock.holds.contains(tid))&#123; // 重入共享锁 - 不记录 return; &#125; // 锁空闲、是共享锁、有排他申请共享，这几种都放行 // 获取到锁后，记录已获取状态 pageLock.stateIncrement(1); // 共享数量+1 pageLock.holds.add(tid); addToLookups(tid, pid);\t&#125;&#125; 申请排他锁： 1234567891011121314151617181920212223242526272829public void acquireExclusiveLock(TransactionId tid, PageId pid) throws TransactionAbortedException &#123; PageLock pageLock = getPageLock(pid); synchronized(pageLock)&#123; // 只要锁不空闲，就不能获取排他锁（除非锁升级） while(pageLock.getLockState() != 0)&#123; // 该事务已经获取了共享锁，且它独占 if(pageLock.getLockState() == 1 &amp;&amp; pageLock.holds.get(0).equals(tid))&#123; // 升级为排他锁 - 放行且不记录 pageLock.stateIncrement(-2); // 此时lockState变-1 return; &#125;else if(pageLock.getLockState() == -1 &amp;&amp; pageLock.holds.get(0).equals(tid))&#123; // 该事务已经获取了排他锁，又重入 - 放行且不记录 return; &#125; try &#123; // 否则阻塞 pageLock.wait(10); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; &#125; // 获取到锁后，记录已获取状态 pageLock.stateIncrement(-1); pageLock.holds.add(tid); addToLookups(tid, pid); &#125;&#125; 这里直接在方法上加 synchronized 也是可行的，但是这样需要每次 notifyAll 所有阻塞的线程，针对性不强。因为每个页面有一个锁，不妨对 pageLock 加锁，这样每次只需 notify 一个阻塞在本页面的线程即可。注意后者需要在 wait 的时候设定等待超时时间，因为会出现别的线程先 notify 后，本线程才进入 wait 的情况，会永久阻塞下去，而设置超时时间后就会不停的循环判断锁条件。这是 wait/notify 方法的固有问题，如果想避免可以用 Semaphore 等其他工具。 释放锁： 12345678910111213141516171819public void releaseLock(TransactionId tid, PageId pid)&#123; PageLock pageLock = getPageLock(pid); synchronized(pageLock)&#123; pageLock.holds.remove(tid); // 从持有者中去除 removeFromLookups(tid, pid); // 从查询表中去除 if(pageLock.getLockState() == -1) &#123; // 如果当前为排他锁，更新为空闲 pageLock.stateIncrement(1); &#125;else if(pageLock.getLockState() &gt; 0)&#123; // 如果当前为共享锁，持有数-1 pageLock.stateIncrement(-1); &#125; // 当没有事务拿着锁了（空闲状态），或只有一个事务拿着锁（可能有锁升级不成功从而等待的情况） if(pageLock.getLockState()==0||pageLock.getLockState()==1)&#123; // 唤醒该页面阻塞的某个事务去竞争空闲锁或升级锁 pageLock.notify(); &#125; &#125;&#125; 死锁检测检测死锁通常是通过事务之间的等待关系图是否有回路（循环等待）来判断，具体的方法有两种： 拓扑排序：反复寻找一个入度为 0 的顶点，将顶点从图中删除并同时删除它的所有出边，如果最终图中全部剩下入度为 1 的顶点，则图中有回路；如果最终全部顶点都被删除，则不包含回路。 DFS：从所有的点开始进行深度优先搜索，如果一条 DFS 路线中有顶点被第二次访问到，则图中有回路，否则不包含回路。 本实验采用 DFS 方法。 设计死锁检测器类 DeadlockDetector： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class DeadlockDetector &#123; // 图的邻接表 private Map&lt;TransactionId, List&lt;TransactionId&gt;&gt; adjList; // 顶点状态 - null/0:未访问，1:已访问，2:在递归栈内 private Map&lt;TransactionId, Integer&gt; nodeState; public DeadlockDetector()&#123; adjList = new ConcurrentHashMap&lt;&gt;(); nodeState = new ConcurrentHashMap&lt;&gt;(); &#125; // 阻塞将要发生 - 进行记录 public void blockOccurs(TransactionId tid, List&lt;TransactionId&gt; listToWait)&#123; adjList.put(tid, listToWait); &#125; // 事务被唤醒 - 删除记录 public void notified(TransactionId tid)&#123; adjList.remove(tid); &#125; // DFS检测是否有回路 public boolean detectCycle()&#123; nodeState.clear(); for(TransactionId tid:adjList.keySet())&#123; if(dfs(tid))&#123; return true; &#125; &#125; return false; &#125; private boolean dfs(TransactionId tid)&#123; nodeState.put(tid, 2); // 标记入递归栈 List&lt;TransactionId&gt; adj = adjList.get(tid); if(adj != null)&#123; for(TransactionId t:adj)&#123; // 跳过自反边的情况 - 单个锁升级等待不算死锁 if(tid.equals(t)) continue; int state = nodeState.getOrDefault(t, 0); if(state == 2)&#123; return true; // 找到环 &#125;else if(state == 0 &amp;&amp; dfs(t))&#123; // 递归 return true; // 找到环 &#125; &#125; &#125; nodeState.put(tid, 1); // 出递归栈，标记已访问 return false; &#125; 为了简便，不再设计顶点类，而是让每一个 TransactionId 代表自己的顶点，采用图的邻接表表示法。nodeState 记录 DFS 中顶点的状态。 每当发生一个阻塞就调用 blockOccurs 方法，因为是页面级的锁定，所以一个事务陷入阻塞后一定等待的是持有页面锁的所有事务，也就是 PageLock 里面 holds 列表所存储的事务。所以我们只需每次将 holds 传入第二个参数，当做该事务顶点的所有出边（表示等待）即可。当事务获得锁（或者发现死锁）后，调用 notified 方法删除该顶点的所有出边。 更新获取共享锁的代码如下（循环部分）： 1234567891011121314151617...while(pageLock.getLockState() == -1 &amp;&amp; !pageLock.holds.get(0).equals(tid))&#123; deadlockDetector.blockOccurs(tid, pageLock.holds); // 添加等待边 if(deadlockDetector.detectCycle())&#123; // 检测到死锁 deadlockDetector.notified(tid); // 移除等待边 // 抛出异常，SimpleDB会abort该事务 throw new TransactionAbortedException(); &#125; try &#123; pageLock.wait(10); deadlockDetector.notified(tid); // 移除等待边 &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125;&#125;... 获取排他锁同理。 DEBUG 记录 PageCache 中的 page 数量可能会小于 LockManger 中的 page 数量，所以在根据 LockManager 中的 Page 来 flush 的时候需要进行 null 判断。 在 Transaction system test 的 10 个线程测试中，出现了时而成功时而永久阻塞的情况。经过调试， 发现是在 flushAllPages() 的循环里卡住； 发现 pageCache 返回的 Iterator 会不停的给出同一个 next 页面，死循环； 发现原因是自定义的双向链表尾结点 tail 丢失链接，导致无法停止遍历； 发现是没有注意线程安全的问题。在之前实现 LRUBasedPageCache 的时候没有使用 ConcurrentHashMap 类和 synchronized 关键字，导致并发问题，修改之后就没有问题了。 多线程情况下，所有的 Map 都最好用 ConcurrentHashMap，List 最好用 CopyOnWriteArrayList，它们除了是线程安全的，还支持遍历时修改，不会报并发修改异常。 在实现死锁检测的时候要注意：当一个事务已经获取共享锁，又要升级为排他锁，此时如果共享数不为 1，那么就要阻塞，但这个时候就会出现自己等待自己的情况（等待图中体现为自反边），但这不是死锁（因为其他的共享锁事务在 release 时会进行唤醒，当共享数为 1 时就不继续等待了），不应该被识别。所以在 DFS 的时候要跳过自反边。"},{"title":"MIT6.830 SimpleDB 实现笔记 Lab 1","path":"/2023/07/07/Lab 1/","content":"6.830 是 MIT 的一门数据库课程，它的 Lab 是用 Java 写一个简易的数据库 SimpleDB。 Lab1 总共有 6 个 exercise，主要是练习的是数据库的数据存储部分。 Exercise 1 src/java/simpledb/storage/TupleDesc.java src/java/simpledb/storage/Tuple.java 在 SimpleDB 中，逻辑上的存储单元由大到小分别是 Database -&gt; Table -&gt; Tuple -&gt; Field。一个表中的每一条记录就是一个 Tuple 元组对象，元组中的每一列是一个 Field 字段值，目前只实现了 Int 和 String（固定长度）类型。 每个元组需要一个 TupleDesc 对象来描述该元组包含的所有字段，包括每个字段类型 fieldType 和字段名 fieldName，在 SimpleDB 中由 TDItem 对象存储。 在实现 TupleDesc 的 toString() 方法时，发现了一个显而易见但之前没注意到的问题：集合每次在调用 iterator() 方法时都会生成一个新的 Iterator，所以不能反复调用此方法。另外 for-each 语句不能用于 Iterator，只能用于数组或实现了 Iterable 接口的对象。 Exercise 2 src/java/simpledb/common/Catalog.java Catalog 是管理数据库所有表的单例对象，比较简单。 主要实现了供外界调用的 addTable、getTableName 等方法 在 SimpleDB 中，一个 Table 对应一个 DbFile，并且共享同一个 ID（DbFile 绝对路径的 hashcode） 这里的 HashMap 用并发安全的比较好 Exercise 3 src/java/simpledb/storage/BufferPool.java 实现 getPage() 方法 BufferPool 也是一个全局单例对象，它负责维护访问页面 Page 的缓存。关于页面，有三个容易混淆的概念： 硬盘中的页面（也可以叫块 block） 操作系统中的页面 数据库中的页面Page 是数据库向硬盘中读取和写入一次数据的最小单位，一般来说数据库的页面比底层的页面要大一些，所以需要我们自己写一些逻辑来保证操作的原子性（暂时不需要）。 每次通过 PageId（存储 tableId 和 pageNo）来获取页面。首先查找缓存，没有的话就通过 Catalog 获取 DbFile 读取页面并加入缓存。如果缓存占满，就要进行页面置换（暂时不需要）。 1234567891011public Page getPage(TransactionId tid, PageId pid, Permissions perm)\tthrows TransactionAbortedException, DbException &#123;\tPage res = idToPage.get(pid);\tif(res == null) &#123; Catalog catalog = Database.getCatalog(); DbFile f = catalog.getDatabaseFile(pid.getTableId()); res = f.readPage(pid); idToPage.put(pid, res);\t&#125;\treturn res;&#125; Exercise 4 src/java/simpledb/storage/HeapPageId.java （继承自 PageId） src/java/simpledb/storage/RecordId.java src/java/simpledb/storage/HeapPage.java （继承自 Page） 前两个 Id 对象主要就是 hashcode() 和 equals() 方法的编写，注意： 在重写一个类的 equals 方法的时候，必须同时重写 hashCode 方法。否则的话，在使用需要判断 hash 值的数据结构（如 HashMap）进行存储时就会出现问题。要求： equals 为 true 时 hashCode 一定为 true；hashCode 为 true 时，equals 不一定为 true。 HeapPage 是实际存储在缓存中的页面（从硬盘读取到内存），它主要包含头部 header 标志位和一个固定长度的 tuple 数组（slots），结构示意图如下： 页面中的 slot（插槽）有几个，header 就有几位，当一个元组插入 slot 后，header 对应位置设置为 1，删除元组则反之。在 SimpleDB 中，一个 table 的 TupleDesc 确定下来后，tuple 的长度就是固定的，因此可以计算出该页面可以有多少个 slot，用于初始化 header 和数组。 计算 slot 个数： 123456private int getNumTuples() &#123; // 每个页面可存储的元组数计算公式（大小单位是字节）：\t// 页面大小 * 8 / (元组大小 * 8 + 1)，向下取整\tint numTuples = BufferPool.getPageSize()*8 / (td.getSize()*8+1);\treturn numTuples;&#125; +1 是因为每个元组要附带一个标志位。 计算 header 大小（字节），多余的 0 位不考虑： 12345private int getHeaderSize() &#123; // Header要存储numSlots个bit，计算所需的bytes\tint headerSize = (int) Math.ceil(numSlots / 8.0); // 向上取整\treturn headerSize;&#125; HeapPage 在初始化时接受一个 pageId 和从硬盘读入的序列化后的 byte 数组进行反序列化，相反，getPageData 方法将该页面序列化以存入硬盘。 需要实现 isSlotUsed() 方法，该方法返回某个 slot 是否插入了元组。检查 header 对应位置的标志位是否为 1 即可。 12345public boolean isSlotUsed(int i) &#123;\t// 注意规定了从每个byte从右到左（low to high）\tbyte slot = (byte) ((header[i/8] &gt;&gt; (i%8)) &amp; 1); return slot == (byte)1 ? true : false;&#125; Exercise 5 src/java/simpledb/storage/HeapFile.java （继承自 DbFile） HeapFile 对应一个表在硬盘中存储的文件，存储的单位是 HeapPage，所以主要是实现 readPage() 方法，它接受 pageId，需要找到对应 Page 在文件中的偏移量读取出来。一定要用文件随机读取，而不能一次性全部读到内存中，因为文件可能会很大。 12345678910111213141516public Page readPage(PageId pid) &#123;\t// 找到对应Page所在的偏移量，读取后生成HeapPage\tint pageSize = BufferPool.getPageSize();\tint offset = pid.getPageNumber() * pageSize;\tbyte[] data = new byte[pageSize];\tPage heapPage = null;\ttry (RandomAccessFile f = new RandomAccessFile(file, &quot;r&quot;)) &#123; f.seek(offset); f.read(data); heapPage = new HeapPage((HeapPageId)pid, data);\t&#125; catch (IOException e) &#123; e.printStackTrace();\t&#125; return heapPage;&#125; 另外的一个难点是实现 iterator() 方法，它的功能是遍历该表（DbFile）中的所有元组。那么就需要我们遍历 HeapFile 的所有 HeapPage，过程中使用 HeapPage 的 Iterator 来遍历元组。但是上面实现的 readPage() 方法是给 BufferPool 调用的，因为所有的页面读取都要经过缓存。所以我们需要调用 BufferPool 的 getPage() 方法来获取页面，从 pageNo = 0 开始累加，直到到达该文件所存储的页面数量的上限，是在 numPages() 里计算得到的（文件大小除以 PageSize）。 Exercise 6 src/java/simpledb/execution/SeqScan.java （实现 OpIterator） Operator 是执行计划的基本单位，最简单、最底层的一个 Operator 就是 SeqScan，按照存储顺序扫描某一个表的全部元组。 这里主要添加了表的别名 alias的概念，我们需要生成一个 tableAlias.filedName 形式的 TupleDesc 以供后续使用。 实现 OpIterator 接口的全部方法，主要是调用 HeapFile 里的 Iterator 的相应方法。"},{"title":"RDD分区与并行计算","path":"/2023/04/05/RDD分区与并行计算/","content":"分区应该是 Spark 中最基础、最核心的概念了，首先搞要清楚为什么要分区。不分区，分布式并行计算就无从谈起。其实哪怕不是分布式，就是如今在一台电脑上 8 个核心也都是标配了，如果把所有的计算任务全都交给一个核心处理便是对硬件资源的极度浪费，效率也十分低下。而要想不浪费，就要采用 并行计算 ，让每一个核心处理一部分任务。而不同的计算需要独立的上下文环境，这就引入了 分区 的概念。每个分区拥有自己的数据和计算函数，当所有的分区计算完毕后，再将它们的结果合并输出。 Spark RDD 在逻辑上实现了以上的分区概念。 第一，在 Spark 中几乎所有功能的数据操作都是以 RDD 为单位的（当然还有累加器和广播变量，但是它们都有固定的应用场景），所以它可以看做在 Spark 中的一个“万能数据集”，不论什么数据都能往里面放，不论在哪个场景都可以用，首先明确这一点（其实是为了打破初学者对它的陌生感）。 第二，所谓分区（Partition），简单来讲就是 RDD 在内部将数据分成的不同 切片 ，从不同的数据源读取数据会按照不同的方式进行切片，因此不同的数据源往往会对应不同类型的 RDD 实现类，而每个 RDD 实现都有一个独立的 Partition 实现类来处理数据。在 Partition 实现类中，会用不同的方法存储实实在在的数据。不过这里要搞清楚，RDD 是惰性计算的，只有在执行行动算子后，数据才会在各种不同的 RDD 分区中 计算、接收、传递 ，并不做停留。因此我的理解是，每个 RDD 分区调用它所 依赖的上一级 RDD 的对应的分区计算方法，获得新的分区数据，这本质是一个 链式调用 。这样行动算子会触发数据从读取到一步步计算的链式调用，最终获得计算结果，可以看做分区是固定的，数据一直在变化。 由上所知，在没有发生 Shuffle 的时候，分区数量不变，不同分区之间的计算是 平行的 ，互不干扰，谁快一点谁慢一点都无所谓，重点是它们在同时计算，这就是并行计算。而在遇到了像 groupByKey、orderBy 这样的需要打乱原有数据的方法，分区之间不可能再相安无事了，它们需要相互交换数据，即进行 Shuffle。Shuffle 操作需要数据 落盘 因此十分低效。而当发生 数据倾斜 时，Shuffle 又能够有效地保证计算的 负载均衡 。 第三，RDD 在逻辑上实现了分区，而在集群上实际的计算如何实现的呢？这就要提到 RDD 的任务执行单位：Job、Stage、Task。简单来说，Job 对应一个行动算子，它内部通过 RDD 谱系图 划分 Stage，通常是遇到一个 Shuffle 操作会生成一个新的 Stage。每个 Stage 根据 RDD 的分区数目生成 Task，一个 Task 对应一个分区。注意 Task 运行的结果是目标 RDD 的一个分区，而不是相反。前两个仍然是逻辑上的，真正可以运行的是 Task。Task 是在 Executor 上运行的，每一个物理节点可以起一个或多个 Executor。 所以最终的运行模型是：Driver 端（就是写 Spark 程序的地方）生成 SparkContext 作为和 Spark 框架连接的入口，它会进行 DAG 图构建、Stage 划分、Task 生成等一系列操作，这些操作是在一个节点完成的。而封装好的 Task 会发送给 Yarn 等调度器进行调度，可能会根据 “计算向数据移动” 等准则分发给不同的节点的 Executor，从而进行计算。 知识点： RDD 计算时（行动算子）在 一个分区 内是一个一个数据根据谱系图执行逻辑，即前面一个数据的逻辑全部执行完毕后才轮到下一个数据。分区内部的数据执行是 有序的 ，不同分区之间的数据执行是 无序的 。 MapPartitions 可以以分区为单位进行数据转换操作，但是会将整个分区的数据加载到内存中进行引用，容易出现内存溢出。 窄依赖： 如果新生成的 child RDD 中每个分区都依赖 parent RDD 中的一部分分区，那么这个分区依赖关系被称为 NarrowDependency。 宽依赖： 表示新生成的 child RDD 中的分区依赖 parent RDD 中的每个分区的一部分。"},{"title":"数据可视化","path":"/2023/04/03/数据可视化/","content":"生活中数据可视化无处不在，以前都会有意无意地进行过可视化的工作，但是通过专业化的分析和方法设计出的结果会更能达到可视化的目的，设计过程也会更加得心应手。另外数据可视化有时候并不只是数据的展现，还包含着数据的挖掘。比如看到一批数据，从不同的角度和考量进行可视化可能会从中挖掘出不同的信息。 本文是北京大学袁晓如老师《数据可视化》课程的学习笔记链接：数据可视化 - 华文慕课 - 中文MOOC平台 (chinesemooc.org) 第 1 章概念 数据可视化就是把一些复杂的数据转化成人们能够直接看到并理解的图形或图像，有利于我们更快地识别特征，发现知识。基于计算机的可视化系统通过对数据的视觉表达形式来帮助人们更有效地完成特定任务。 不同的领域、不同的任务、不同的受众的可视化构型是不同的，要做合理、有效的选择。 要考虑计算限制、人类限制、显示限制 总结第一章讲述了可视化的概念、构型和案例，其中构型的选择非常重要，需要考虑不同的领域、任务、受众和限制因素，要在多对矛盾中进行权衡。 第 2 章数据类型 数据集类型 结构化数据：已知数据类型、语义 表格（Tables） 网络（Networks） 场（Fields） 空间/几何（Spatial/Geometry） 多维表（Multidimensional Table） 树形（Trees） 非结构化数据：没有预定的数据模型，如文字、视频、图像。需要转化为结构化数据（NPL、文本挖掘） 数据类型：数据项、链接、属性、位置、网格 属性类型：定类型、定序型、定量型。不同的属性需要用不同的通道表示。看到一个可视化就分析有什么属性，看到属性就要想是什么类型。 表达力和有效性：服从一致性和重要性排序原则，一致性是指，视觉变量和数据属性应该匹配。 2.7 的设计案例有启发意义。 总结这一章主要介绍了各类数据集合数据的类型，目的是强调在可视化过程中，对属性类型的分析是十分重要的，不同类型的属性需要考虑不同的可视化方法，这决定着最后的呈现效果（千差万别）。要培养分析数据属性的思维。 第 3 章数据编码（具体步骤） 符号和通道 符号标记（Marks）：如用圆点和直线代表数据项和连接 点、线、面，（包含、连接、嵌套） 视觉通道（Channels）：符号标记的表现形式，如圆点的颜色 分为以下两个类型，顺序代表有效性从高到低 &lt;定类型&gt; ：空间区域、颜色、运动模式、形状 &lt;定序定量型&gt; ：位置、长度、倾斜度、面积、深度、亮度/饱和度、弧度、体积 考虑视觉通道的五个属性：选择性、关联性、量化性、可序性、容量 史蒂文心理物理强度定律：强度由高到低：饱和度、长度、面积、深度、亮度，感官测试：The eyeballing game (woodgears.ca) 不同类别应该采取的通道排序：image.png 总结直观地感受了各类视觉通道的差异和优缺点，在可视化的时候首先要选择正确的符号和通道，让人们有对数据更加准确的感受。 第 4 章可视化任务与分析 分析三要素： 对象：判断第二章所述的数据类型和属性类型 手段：将第三章所述进行实践 目的：考虑用户需求（什么样的用户） 可视化任务抽象。不同的可视化有不同的任务，这里的任务（功能）是从用户的角度出发，用户为什么需要可视化，该可视化想要用户得到什么信息。要识别任务-数据组合，寻找可能的解决方案。即分析三要素中的目的（行动和对象），行动有以下三个层次（由高到低）：分析、搜索、查询。image.png image.png 分析三要素中的对象，对于不同的对象关心不同的特点： image.png 分析三要素中的手段，考虑可视化构型：视觉编码、交互。（后面讲） 可视化设计验证四层模型：image.png 所谓问题导向就是某个领域的某个问题需要可视化，这时四层模型从外到内进行工作。所谓技术导向就是某个新型的可视化技术出现了，从内到外去寻找可以可视化那些领域问题。 详细学习 4.5 可视化案例。 总结讲述了可视化过程中需要完成哪些分析工作，有哪些要素。从一个顶层抽象的角度阐述了可视化的整个流程。 第 5 章交互 视图操纵的方法 视图随时间变化 重新编码，对于对象 调整参数，不同的小控件（滑块、按钮等） 调整布局、顺序，What、How、Why 重排，对复杂的表格不同的维度（Table Lens）/ 平行坐标 调整对齐方式，堆叠柱形图 过渡动画，在两个状态间做插值平滑 视图分面（Facet） 并置视图（重要）：把两个图放在一起关联 image.png，动态查询是一个经典的例子，快速、增量式和可逆的交互操作。 分隔视图 image.png 叠加视图 image.png 数据约简（Reduce） 过滤：交叉过滤（一个维度变化，另外跟着变） 聚合：空间聚合 不完全互斥可视化系统：Jigsaw总结讲述了可视化中最有趣但却做复杂的交互操作，介绍了视图操纵的几种方法，通过例子体会到不同交互方法的特点和功能，恰当的交互能够给用户带来良好的体验的同时，也能够让用户有更多的发现。 第 6 章光与颜色 颜色表现不止于单一的颜色，还要考虑背景色，和周围的颜色（上下文）。 环境颜色会增加其自身的相反颜色以获得更强的对比 深色增加浅色 红色增加绿色 蓝色增加黄色 感知差异依赖于背景 颜色模型：《CIE 标准观测》 色度图 RGB 色度（三角形） 投影色域 对立色彩 颜色设计准则（经验） 需要考虑上下文，这里的上下文是指除颜色设计之外的各种对象与概念。（比如用户和预算等） 并不是五彩缤纷就是好的，好的设计让信息更吸引人。 颜色包括 &lt;色相、饱和度、亮度&gt; 三个属性，要精确区分。 控制明度，确保易读性 控制色相种类，定义颜色分组，避免太多颜色竞争而混乱，控制“弹出效应” 使用中和背景，最小化 “同时对比效应” 在不同的可视化场景，根据颜色标注的目标不同，颜色的选择也不同。比如飞机上的仪表盘属于需要快速反应的场景，颜色不能太多。 ColorBrewer: Color Advice for Maps (colorbrewer2.org) 网站提供不同的配色方案。 总结在使用颜色的时候需要考虑很多因素，比如对比、色盲等。在设计的时候需要遵循设计准则，让颜色起到增进理解而不是相反的作用。首先要理解颜色的各种属性，精确区分，谨慎选择。 第 7, 8 章表格表格分为平面表格（唯一索引）和多维表格（基于多个键的索引）。 平面数据 表格数据的比较 条形图（可以有不同方向）：要注意基准问题（起始值是否从 0 出发）；要注意是用线性变换还是对数变换，这里的变换是指纵轴单位长度的变化。 折线图：可用【光滑】【连接】和【散点】。要注意如果两个数据点之间连接起来，代表这个属性是可以插值的（比如年龄），如果属性不能插值（比如性别分类）则不能随意连接起来。 散点图：常常用于揭示两个维度之间的相关性。如果有第三维的话，可以将其映射到其他的视觉属性，比如颜色、大小；要注意不要过度绘制，要善用透明度和趋势线。 饼图/圈图：用于表示数据的组成。强调精确数值时用条形图，强调比例时用饼图。 堆叠条形图：将圈图拉直放到坐标系中，比饼图更加直观。 堆叠面积图：将离散的堆叠条形图连接起来。 表示数据的分布的图： 【直方图】与柱状图的区别是没有间隙，横轴是某个属性的区间划分；经验法则：根据数据量的平方根来确定划分区间的数目。 【密度图】 【箱型图】 【小提琴图】 【热力图】 表格可视化经典方法：Table Lens（表格透镜） 高维数据 散点图：点的位置表示两个属性，点的大小、颜色表示更多的属性，但往往表示不了高维（大于三个维度）。 散点矩阵图：每行/列是一个维度，每个单元格绘制两个维度的散点图。下图是 4 个维度两两之间的关系：image.png SPLOM 聚合-热力图：类似于散点图，减少计算量。image.png 相关热力图 Rolling the Dice：两个散点图无缝转换 平行坐标：将 x,y,z 等坐标轴平行放置，可以引入更多的维度，一条连线代表一个数据项，适用于异构数据。当数据量较大的时候，采用 &lt;增加透明度、捆绑、采样&gt; 来解决杂乱问题。 image.png 降维：保留尽可能多的变化，绘制低维空间，主成分分析。 多维缩放：让两两之间在平面的距离尽量正比于在高维空间的距离。常用于文本分析。 地形图表示。 维度嵌套/堆叠： 维度有限，工程数据分析常用 多方法耦合：平行坐标+散点图 其他方法：太多了，看 8.6 节 总结详细讲述了各种图对于表格数据可视化的作用，适当进行选取。 第 9, 10 章网络结构 层次结构（树）：用于有组织结构、分级分类的数据，有谱系树、进化树、搜索树、决策树。 显式树可视化 Reingold-Tilford 布局：类似思维导图 DOI 树（突出焦点）：树节点过多，只强调部分节点（增大），或用三角形代表不重要的子树。 双曲线树（突出焦点）：面向大规模的层次结构数据，全体数据可见，焦点放大。image.png 隐式树可视化：看不见树的结构，但是树的内部关系。较重要的是包含式非显式布局。其中最重要的是【树图】（Treemap）：切分空间，节点为长方形，节点面积代表相应属性。 树比较可视化：用柱状图进行树之间的比较。 图的可视化 两种主要类型的任务：【基于属性】、【基于拓扑】。 显式图形式：image.png，布局标准如下，减少用户阅读的干扰（不用全部满足）： 最小化边交叉 最小化相邻接点的距离 最小化绘图区域 边长度统一 最小化边弯曲 最大化不同边之间的角距离（过多的锐角不容易分辨） 宽高比约为 1（不太长也不太宽） 对称性（类似的图结构看起来相似） 矩阵形式：即图的邻接矩阵。非常适合邻域相关的任务，不适合路径相关的任务；节点的顺序很重要，排序后可能会发现规律。 混合显示与矩阵形式：NodeTrix。image.png 力导向布局算法：边=弹簧，点=互斥磁铁，算法开销较大 image.png 总结不同可视化方法之间需要进行取舍，为了相应的目的，可能会降低对另外一部分性能的支持。不同的可视化方法可以混用，可能达到更好的效果。 第 10 章时间序列时间序列数据就是其中一个变量是时间的数据，也可以说是高维中一个维度是时间的数据。vcg.informatik.uni-rostock.de可视化方法有： 缩略组图（Small Multiples）：在单个页面上显示的呈缩略图大小的图形集，表示单个现象的不同方面（不同时间）。也适用于多变量（多维）显示。比如新冠晴雨表。 形态替换：将时间视为隐藏的维度，为每个时间帧生成一个可视化，然后播放动画，用户可以进行追踪（可以加上轨迹）。Gapminder Tools 。但是该方法有一个问题是变化盲视，即人们没有注意到场景中可见元素的变化，需要根据具体情况解决（如增加视觉编码）。 时间序列图：将横坐标规定为时间，纵坐标为属性（可以有多个，不同编码也可以嵌套堆叠）。对于多个时间序列的比较，有以下几种方法： 简单线图：多条不同的线在一起。 编织线图：交替地根据数值的大小进行前后排列。 计算曲线焦点并垂直切割曲线面积，按照深度排序优先绘制最高部分面积。 换句话就是：高个子永远在后面。 image.png 缩略视图：见前文。 水平线图：解决缩略视图在高度较小的情况下空间利用问题。（压缩高度，保留精度） 堆叠线图：把不同的线型堆叠在一起。 螺旋图：更好的体现周期性；注意比例和标注。 像素驱动方法：每个像素代表一个时间点。 一行行/一列列排布 用填充曲线（Peano-Hilbert）：时间上相近的，空间上也相近。 时间曲线（Time Curves）：时间顺序的排列并不是规则的（水平的），而是根据内容相似性进行分布（弯曲）。曲线的形状可以表示相应的演变。（高维映射到低维 / 多维缩放） 主题河流（ThemeRivers）：表示文本随时间的变化。 从左到右流经时间，类似堆叠曲线图 image.png 总结时间在可视化里面可以看做高维中的一个带有先后顺序的属性，所以时间序列可视化都是在视觉上具有一定的连续性，这种联系可以让人们更直观地感受时间的流动与事物的变化。 第 12 章地图 使用地图的原则和任务 原则：当空间关系被着重强调时使用地图 任务：寻找地点/特征、寻找从 A 到 B 的路径、辨认与地点相关的属性、基于地点比较属性 地图投影 - 将地球展开 要考虑的属性：面积、形状、方向、方位、距离、尺度 投影方法 墨卡托投影：投影至一个包裹着地球的圆柱上，再展开成平面。所有的经纬线都是直线前垂直相交；方位准确，面积不准确。 方位角等距投影：确定航线走向。image.png 温格尔投影：最小化三种失真（面积、方向、距离）。image.png 锥形投影 阿尔博斯等面积投影：正确显示面积 复合投影 其他投影方式：Extended geographic projections for d3-geo. (github.com) 区域分布地图 用区域填充的颜色或图案来表示数值，如美国大选地图 问题：具有误导性，因为某区域面积的大小可能与数值没有关系 解决方法：同一个颜色用深浅区分数值大小，或加入其他编码（如密度） 等高线地图：用来表述在空间中的数值分布，特别是数值之间的过渡。 统计/变形地图：舍弃了地理区域的真实面积，而用数值大小来决定面积（缩放），但保留了原地理区域之间的方位、接壤等信息。 比例标识地图：保留原地理区域的真实面积，而采用添加圆圈（或其他图形），用它的的大小或其他定量属性来代表数值的大小。 流图：用于表示数据在不同地域之间的流动。（交通部门） 地铁地图：采用伦敦地铁图方式。线路水平、垂直或 45 度，车站间等距。 总结地图可视化都是以真实的地理区域为基础，而自然地理区域的面积、方位是固定的，想要表示的数据又往往与面积、方位无关，这就需要考虑如何规避掉区域自然属性对可视化目的的干扰。 第 13 章经验法则大多数情况下简单的、经验性的、探索性的但不是很准确的原则，体系不完整。 慎用 3D（但是技术在发展） 屏幕不是三维的，更适合 2D 信息 人对深度的判断不够精确 会产生遮挡，无法了解相关关系，带来时间成本 透视会引起失真 3D 下的文本会倾斜，造成认知负荷 慎用 2D：能用 1D 的列表就不要用 2D，1D 更适合查找、排序任务。在可视化里面，能简则简，不要追求复杂（越简洁越有效）。 慎用多视图的简单组合：缺乏数据内在逻辑的关联，无法提供深度探索。多视图需要有侧重点，图与图之间要紧密联系，有紧密的交互。（有机结合） 可见性重于记忆：如果能够通过不同视图直接对比，就不要采用动画，因为动画要求用户记忆，带来负担。 分辨率优先：沉浸感依赖于分辨率。简单说就是优先提高分辨率，而不是整花里胡哨的东西。 概览优先，缩放与过滤，细节按需呈现：【大量数据 -&gt; 展示概览，忽略细节 -&gt; 提供提示 -&gt; 用户定位到感兴趣的地方 -&gt; 放大 -&gt; 涌现细节】 交互响应不可缺少：即时反馈非常重要，如不能即时，应告知用户处理进度或先显示一部分。 黑白情况下的可用性：可视化在黑白情况下依然有效。借用亮度、色度、饱和度等通道。 功能重于形式：坚持有效性优先原则，考虑用户需求。 总结经验法则是贯穿于所有可视化技术的原则，在进行可视化工作之前和完成之后，都可以对照经验法则检验工作是否得当。"}]